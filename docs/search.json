[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Functions of the Week",
    "section": "",
    "text": "Functions of the Week\n\nBSTA526 Winter 2024\n\nR Programming for Health Data Science\nOHSU-PSU School of Public Health\nOregon Health & Science University\n\n\n\n\n\n\n\n\n\n\n\n\n View the source on GitHub"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "Functions of the Week",
    "section": "",
    "text": "Below are links to students’ Function of the Week submissions.\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\n2/7/24\n\n\nn_distinct\n\n\nThe n_distinct() function counts the number of unique values in a vector\n\n\n\n\nInvalid Date\n\n\ndplyr::slice_sample\n\n\nUpdate with brief descirption of function\n\n\n\n\n2/7/24\n\n\nlubridate::ceiling_date()\n\n\nUsed for rounding a given date-time object up to the nearest boundary of a specified time unit\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "presentations/function_of_the_week_ECHALUSE.html",
    "href": "presentations/function_of_the_week_ECHALUSE.html",
    "title": "lubridate::ceiling_date()",
    "section": "",
    "text": "In this document, I will introduce the ceiling_date() function and show what it’s for.\n\nlibrary(lubridate)\n\n\n\nThe ceiling_date() function is part of the lubridate package. It is used for rounding a given date-time object up to the nearest boundary of a specified time unit.\nThe term  ceiling  means rounding up, and users can specify rounding up to the nearest second, minute, hour, day, week, month, or year.\n\nceiling_date(x, unit=c(\"second\", \"minute\", \"hour\", \"day\",\n    \"week\", \"month\", \"year\"))\n\n\n x  is a vector of date-time objects.\n unit  is a string, period object, or date-time object rounded to the nearest boundary of a specific time unit.\n\n\n\nExample #1\n\n\n# format: year/month/day hour/minute/second\nx &lt;- ymd_hms(\"2009-08-03 12:01:59.23\") # Monday\n\n\n# rounding\nceiling_date(x, \"second\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"minute\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"5 mins\")\n\n[1] \"2009-08-03 12:05:00 UTC\"\n\nceiling_date(x, \"hour\")\n\n[1] \"2009-08-03 13:00:00 UTC\"\n\nceiling_date(x, \"2 hours\")\n\n[1] \"2009-08-03 14:00:00 UTC\"\n\nceiling_date(x, \"day\") # Tuesday\n\n[1] \"2009-08-04 UTC\"\n\nceiling_date(x, \"week\") # Saturday\n\n[1] \"2009-08-09 UTC\"\n\nceiling_date(x, \"month\")\n\n[1] \"2009-09-01 UTC\"\n\nceiling_date(x, \"year\")\n\n[1] \"2010-01-01 UTC\"\n\n\nReference:\n1. https://lubridate.tidyverse.org/reference/round_date.html\n2. RDocumentation\n\n\nExample #2\n\n\nlibrary(nycflights13)\ndata(flights)\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\nhead(flights)\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n# To convert date and time information into a more standard datetime format.\n# We write a `function()` with parameters: year, month, day, and time.\n# Use `lubridate::make_datetime()` to create a new datetime object (make_datetime_100). \n# The time format is in HHMM and splits the time into hours (time %/% 100) and minutes (time %% 100).\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\n\n# Rows with missing departure or arrival times are filtered out. \n# Use `mutate` to create new columns:\n# departure time, arrival time, scheduled departure time, and scheduled arrival time. \n# The make_datetime_100 function is applied to, and after select columns:\n# origin, destination, columns ending with \"delay,\" and columns ending with \"time\".\n\nflights_dt &lt;- flights %&gt;% \n  filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% \n  mutate(dep_time = make_datetime_100(year, month, day, dep_time),\n         arr_time = make_datetime_100(year, month, day, arr_time),\n         sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n         sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)) %&gt;%\n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\n\n# Check\nhead(flights_dt)\n\n# A tibble: 6 × 9\n  origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n# ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt;\n\nskim(flights_dt)\n\n\nData summary\n\n\nName\nflights_dt\n\n\nNumber of rows\n328063\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\nPOSIXct\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\norigin\n0\n1\n3\n3\n0\n3\n0\n\n\ndest\n0\n1\n3\n3\n0\n104\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndep_delay\n0\n1\n12.58\n40.09\n-43\n-5\n-2\n11\n1301\n▇▁▁▁▁\n\n\narr_delay\n717\n1\n6.90\n44.63\n-86\n-17\n-5\n14\n1272\n▇▁▁▁▁\n\n\nair_time\n717\n1\n150.69\n93.69\n20\n82\n129\n192\n695\n▇▂▂▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndep_time\n0\n1\n2013-01-01 05:17:00\n2013-12-31 23:56:00\n2013-07-04 09:12:00\n211509\n\n\nsched_dep_time\n0\n1\n2013-01-01 05:15:00\n2013-12-31 23:59:00\n2013-07-04 09:15:00\n125557\n\n\narr_time\n0\n1\n2013-01-01 00:03:00\n2014-01-01 00:00:00\n2013-07-04 11:06:00\n220332\n\n\nsched_arr_time\n0\n1\n2013-01-01 00:05:00\n2013-12-31 23:59:00\n2013-07-04 11:20:00\n204384\n\n\n\n\n\n\n# Plot: Departure time\nggplot(flights_dt, aes(x = dep_time)) +\n  geom_histogram(binwidth = 3600, color = \"purple\", alpha = 0.7) +\n  labs(title = \"Departure Time Distribution\",\n       x = \"Departure Time\",\n       y = \"Frequency\")\n\n\n\n\n\n# Plot: Departure for each week\nflights_dt %&gt;% \n  count(week = ceiling_date(dep_time, \"week\")) %&gt;% \n  ggplot(aes(week, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Week\",\n         x = \"Week\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\n\n# Plot: Departure for each month\nflights_dt %&gt;% \n  count(month = ceiling_date(dep_time, \"month\")) %&gt;% \n  ggplot(aes(month, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Month\",\n         x = \"Month\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\nInstead of plotting the original departure time, we can round up to a nearby unit of time using ceiling_date(), and allows us to plot the number of flights per week and per month.\nReference:\n1. R for Data Science. https://r4ds.had.co.nz/dates-and-times.html\n2. How to Write Fuctions in R\n\n\n\nYes, it is useful in representing time in plots and can offer insights into patterns and/or trends over different time intervals. This can be especially true for large datasets where ceiling_date() can be used to simplify and group dates to provide a more concise and interpretable representation of trends. I don’t use this everyday, but I do think it is pretty neat!"
  },
  {
    "objectID": "presentations/function_of_the_week_ECHALUSE.html#what-is-it-for",
    "href": "presentations/function_of_the_week_ECHALUSE.html#what-is-it-for",
    "title": "lubridate::ceiling_date()",
    "section": "",
    "text": "The ceiling_date() function is part of the lubridate package. It is used for rounding a given date-time object up to the nearest boundary of a specified time unit.\nThe term  ceiling  means rounding up, and users can specify rounding up to the nearest second, minute, hour, day, week, month, or year.\n\nceiling_date(x, unit=c(\"second\", \"minute\", \"hour\", \"day\",\n    \"week\", \"month\", \"year\"))\n\n\n x  is a vector of date-time objects.\n unit  is a string, period object, or date-time object rounded to the nearest boundary of a specific time unit.\n\n\n\nExample #1\n\n\n# format: year/month/day hour/minute/second\nx &lt;- ymd_hms(\"2009-08-03 12:01:59.23\") # Monday\n\n\n# rounding\nceiling_date(x, \"second\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"minute\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"5 mins\")\n\n[1] \"2009-08-03 12:05:00 UTC\"\n\nceiling_date(x, \"hour\")\n\n[1] \"2009-08-03 13:00:00 UTC\"\n\nceiling_date(x, \"2 hours\")\n\n[1] \"2009-08-03 14:00:00 UTC\"\n\nceiling_date(x, \"day\") # Tuesday\n\n[1] \"2009-08-04 UTC\"\n\nceiling_date(x, \"week\") # Saturday\n\n[1] \"2009-08-09 UTC\"\n\nceiling_date(x, \"month\")\n\n[1] \"2009-09-01 UTC\"\n\nceiling_date(x, \"year\")\n\n[1] \"2010-01-01 UTC\"\n\n\nReference:\n1. https://lubridate.tidyverse.org/reference/round_date.html\n2. RDocumentation\n\n\nExample #2\n\n\nlibrary(nycflights13)\ndata(flights)\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\nhead(flights)\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n# To convert date and time information into a more standard datetime format.\n# We write a `function()` with parameters: year, month, day, and time.\n# Use `lubridate::make_datetime()` to create a new datetime object (make_datetime_100). \n# The time format is in HHMM and splits the time into hours (time %/% 100) and minutes (time %% 100).\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\n\n# Rows with missing departure or arrival times are filtered out. \n# Use `mutate` to create new columns:\n# departure time, arrival time, scheduled departure time, and scheduled arrival time. \n# The make_datetime_100 function is applied to, and after select columns:\n# origin, destination, columns ending with \"delay,\" and columns ending with \"time\".\n\nflights_dt &lt;- flights %&gt;% \n  filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% \n  mutate(dep_time = make_datetime_100(year, month, day, dep_time),\n         arr_time = make_datetime_100(year, month, day, arr_time),\n         sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n         sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)) %&gt;%\n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\n\n# Check\nhead(flights_dt)\n\n# A tibble: 6 × 9\n  origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n# ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt;\n\nskim(flights_dt)\n\n\nData summary\n\n\nName\nflights_dt\n\n\nNumber of rows\n328063\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\nPOSIXct\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\norigin\n0\n1\n3\n3\n0\n3\n0\n\n\ndest\n0\n1\n3\n3\n0\n104\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndep_delay\n0\n1\n12.58\n40.09\n-43\n-5\n-2\n11\n1301\n▇▁▁▁▁\n\n\narr_delay\n717\n1\n6.90\n44.63\n-86\n-17\n-5\n14\n1272\n▇▁▁▁▁\n\n\nair_time\n717\n1\n150.69\n93.69\n20\n82\n129\n192\n695\n▇▂▂▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndep_time\n0\n1\n2013-01-01 05:17:00\n2013-12-31 23:56:00\n2013-07-04 09:12:00\n211509\n\n\nsched_dep_time\n0\n1\n2013-01-01 05:15:00\n2013-12-31 23:59:00\n2013-07-04 09:15:00\n125557\n\n\narr_time\n0\n1\n2013-01-01 00:03:00\n2014-01-01 00:00:00\n2013-07-04 11:06:00\n220332\n\n\nsched_arr_time\n0\n1\n2013-01-01 00:05:00\n2013-12-31 23:59:00\n2013-07-04 11:20:00\n204384\n\n\n\n\n\n\n# Plot: Departure time\nggplot(flights_dt, aes(x = dep_time)) +\n  geom_histogram(binwidth = 3600, color = \"purple\", alpha = 0.7) +\n  labs(title = \"Departure Time Distribution\",\n       x = \"Departure Time\",\n       y = \"Frequency\")\n\n\n\n\n\n# Plot: Departure for each week\nflights_dt %&gt;% \n  count(week = ceiling_date(dep_time, \"week\")) %&gt;% \n  ggplot(aes(week, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Week\",\n         x = \"Week\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\n\n# Plot: Departure for each month\nflights_dt %&gt;% \n  count(month = ceiling_date(dep_time, \"month\")) %&gt;% \n  ggplot(aes(month, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Month\",\n         x = \"Month\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\nInstead of plotting the original departure time, we can round up to a nearby unit of time using ceiling_date(), and allows us to plot the number of flights per week and per month.\nReference:\n1. R for Data Science. https://r4ds.had.co.nz/dates-and-times.html\n2. How to Write Fuctions in R"
  },
  {
    "objectID": "presentations/function_of_the_week_ECHALUSE.html#is-it-helpful",
    "href": "presentations/function_of_the_week_ECHALUSE.html#is-it-helpful",
    "title": "lubridate::ceiling_date()",
    "section": "",
    "text": "Yes, it is useful in representing time in plots and can offer insights into patterns and/or trends over different time intervals. This can be especially true for large datasets where ceiling_date() can be used to simplify and group dates to provide a more concise and interpretable representation of trends. I don’t use this everyday, but I do think it is pretty neat!"
  },
  {
    "objectID": "presentations/function_of_the_week_McMonigal.html",
    "href": "presentations/function_of_the_week_McMonigal.html",
    "title": "n_distinct",
    "section": "",
    "text": "In this document, I will introduce the n_distinct() function from dplyr and show what it’s for.\n\n#load dplyr\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n#example dataset\ndata(starwars)\n\n\n\nThe n_distinct() function counts the number of unique values in a vector or set of vectors. It has two arguments:\n\n... : One or more vectors from your dataset.\nna.rm : Can equal TRUE or FALSE.\n\nThe default is na.rm = FALSE, meaning missing values are included in the count of distinct values by default. If TRUE, missing values will be excluded from the count of distinct values.\n\n\n\n\n#Let's see what is in our dataset.\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\n#Let's use n_distinct on a categorical variable, such as species.\nn_distinct(starwars$species)\n\n[1] 38\n\n\n\n#Let's examine how na.rm works.\nn_distinct(starwars$hair_color, na.rm = FALSE)\n\n[1] 13\n\n\n\n#Now let's change to na.rm = TRUE\nn_distinct(starwars$hair_color, na.rm = TRUE)\n\n[1] 12\n\n\n\n#Let's try with multiple vectors. Missing values will be included in the count.\nn_distinct(starwars$hair_color, starwars$eye_color)\n\n[1] 35\n\n\n\n#What are the distinct pairs?\nstarwars %&gt;% distinct(eye_color, hair_color)\n\n# A tibble: 35 × 2\n   eye_color hair_color   \n   &lt;chr&gt;     &lt;chr&gt;        \n 1 blue      blond        \n 2 yellow    &lt;NA&gt;         \n 3 red       &lt;NA&gt;         \n 4 yellow    none         \n 5 brown     brown        \n 6 blue      brown, grey  \n 7 blue      brown        \n 8 brown     black        \n 9 blue-gray auburn, white\n10 blue      auburn, grey \n# ℹ 25 more rows\n\n(tibble1 &lt;- starwars %&gt;% group_by(eye_color) %&gt;%\n  summarise(count = n_distinct(hair_color)))\n\n# A tibble: 15 × 2\n   eye_color     count\n   &lt;chr&gt;         &lt;int&gt;\n 1 black             2\n 2 blue              8\n 3 blue-gray         1\n 4 brown             4\n 5 dark              1\n 6 gold              1\n 7 green, yellow     1\n 8 hazel             2\n 9 orange            2\n10 pink              1\n11 red               2\n12 red, blue         1\n13 unknown           2\n14 white             1\n15 yellow            6\n\nsum(tibble1$count)\n\n[1] 35\n\n\n\n\n\nThe function n_distinct() is helpful for data exploration for categorical variables because it quickly counts the number of distinct values.\nHowever, n_distinct() on its own is not very powerful, and the function is more helpful when used in combination with other functions."
  },
  {
    "objectID": "presentations/function_of_the_week_McMonigal.html#what-is-it-for",
    "href": "presentations/function_of_the_week_McMonigal.html#what-is-it-for",
    "title": "n_distinct",
    "section": "",
    "text": "The n_distinct() function counts the number of unique values in a vector or set of vectors. It has two arguments:\n\n... : One or more vectors from your dataset.\nna.rm : Can equal TRUE or FALSE.\n\nThe default is na.rm = FALSE, meaning missing values are included in the count of distinct values by default. If TRUE, missing values will be excluded from the count of distinct values."
  },
  {
    "objectID": "presentations/function_of_the_week_McMonigal.html#example-using-starwars",
    "href": "presentations/function_of_the_week_McMonigal.html#example-using-starwars",
    "title": "n_distinct",
    "section": "",
    "text": "#Let's see what is in our dataset.\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\n#Let's use n_distinct on a categorical variable, such as species.\nn_distinct(starwars$species)\n\n[1] 38\n\n\n\n#Let's examine how na.rm works.\nn_distinct(starwars$hair_color, na.rm = FALSE)\n\n[1] 13\n\n\n\n#Now let's change to na.rm = TRUE\nn_distinct(starwars$hair_color, na.rm = TRUE)\n\n[1] 12\n\n\n\n#Let's try with multiple vectors. Missing values will be included in the count.\nn_distinct(starwars$hair_color, starwars$eye_color)\n\n[1] 35\n\n\n\n#What are the distinct pairs?\nstarwars %&gt;% distinct(eye_color, hair_color)\n\n# A tibble: 35 × 2\n   eye_color hair_color   \n   &lt;chr&gt;     &lt;chr&gt;        \n 1 blue      blond        \n 2 yellow    &lt;NA&gt;         \n 3 red       &lt;NA&gt;         \n 4 yellow    none         \n 5 brown     brown        \n 6 blue      brown, grey  \n 7 blue      brown        \n 8 brown     black        \n 9 blue-gray auburn, white\n10 blue      auburn, grey \n# ℹ 25 more rows\n\n(tibble1 &lt;- starwars %&gt;% group_by(eye_color) %&gt;%\n  summarise(count = n_distinct(hair_color)))\n\n# A tibble: 15 × 2\n   eye_color     count\n   &lt;chr&gt;         &lt;int&gt;\n 1 black             2\n 2 blue              8\n 3 blue-gray         1\n 4 brown             4\n 5 dark              1\n 6 gold              1\n 7 green, yellow     1\n 8 hazel             2\n 9 orange            2\n10 pink              1\n11 red               2\n12 red, blue         1\n13 unknown           2\n14 white             1\n15 yellow            6\n\nsum(tibble1$count)\n\n[1] 35"
  },
  {
    "objectID": "presentations/function_of_the_week_McMonigal.html#is-n_distinct-helpful",
    "href": "presentations/function_of_the_week_McMonigal.html#is-n_distinct-helpful",
    "title": "n_distinct",
    "section": "",
    "text": "The function n_distinct() is helpful for data exploration for categorical variables because it quickly counts the number of distinct values.\nHowever, n_distinct() on its own is not very powerful, and the function is more helpful when used in combination with other functions."
  },
  {
    "objectID": "function_of_the_week_ECHALUSE.html",
    "href": "function_of_the_week_ECHALUSE.html",
    "title": "lubridate::ceiling_date()",
    "section": "",
    "text": "In this document, I will introduce the ceiling_date() function and show what it’s for.\n\nlibrary(lubridate)\n\n\n\nThe ceiling_date() function is part of the lubridate package. It is used for rounding a given date-time object up to the nearest boundary of a specified time unit.\nThe term  ceiling  means rounding up, and users can specify rounding up to the nearest second, minute, hour, day, week, month, or year.\n\nceiling_date(x, unit=c(\"second\", \"minute\", \"hour\", \"day\",\n    \"week\", \"month\", \"year\"))\n\n\n x  is a vector of date-time objects.\n unit  is a string, period object, or date-time object rounded to the nearest boundary of a specific time unit.\n\n\n\nExample #1\n\n\n# format: year/month/day hour/minute/second\nx &lt;- ymd_hms(\"2009-08-03 12:01:59.23\") # Monday\n\n\n# rounding\nceiling_date(x, \"second\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"minute\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"5 mins\")\n\n[1] \"2009-08-03 12:05:00 UTC\"\n\nceiling_date(x, \"hour\")\n\n[1] \"2009-08-03 13:00:00 UTC\"\n\nceiling_date(x, \"2 hours\")\n\n[1] \"2009-08-03 14:00:00 UTC\"\n\nceiling_date(x, \"day\") # Tuesday\n\n[1] \"2009-08-04 UTC\"\n\nceiling_date(x, \"week\") # Saturday\n\n[1] \"2009-08-09 UTC\"\n\nceiling_date(x, \"month\")\n\n[1] \"2009-09-01 UTC\"\n\nceiling_date(x, \"year\")\n\n[1] \"2010-01-01 UTC\"\n\n\nReference:\n1. https://lubridate.tidyverse.org/reference/round_date.html\n2. RDocumentation\n\n\nExample #2\n\n\nlibrary(nycflights13)\ndata(flights)\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\nhead(flights)\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n# To convert date and time information into a more standard datetime format.\n# We write a `function()` with parameters: year, month, day, and time.\n# Use `lubridate::make_datetime()` to create a new datetime object (make_datetime_100). \n# The time format is in HHMM and splits the time into hours (time %/% 100) and minutes (time %% 100).\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\n\n# Rows with missing departure or arrival times are filtered out. \n# Use `mutate` to create new columns:\n# departure time, arrival time, scheduled departure time, and scheduled arrival time. \n# The make_datetime_100 function is applied to, and after select columns:\n# origin, destination, columns ending with \"delay,\" and columns ending with \"time\".\n\nflights_dt &lt;- flights %&gt;% \n  filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% \n  mutate(dep_time = make_datetime_100(year, month, day, dep_time),\n         arr_time = make_datetime_100(year, month, day, arr_time),\n         sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n         sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)) %&gt;%\n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\n\n# Check\nhead(flights_dt)\n\n# A tibble: 6 × 9\n  origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n# ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt;\n\nskim(flights_dt)\n\n\nData summary\n\n\nName\nflights_dt\n\n\nNumber of rows\n328063\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\nPOSIXct\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\norigin\n0\n1\n3\n3\n0\n3\n0\n\n\ndest\n0\n1\n3\n3\n0\n104\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndep_delay\n0\n1\n12.58\n40.09\n-43\n-5\n-2\n11\n1301\n▇▁▁▁▁\n\n\narr_delay\n717\n1\n6.90\n44.63\n-86\n-17\n-5\n14\n1272\n▇▁▁▁▁\n\n\nair_time\n717\n1\n150.69\n93.69\n20\n82\n129\n192\n695\n▇▂▂▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndep_time\n0\n1\n2013-01-01 05:17:00\n2013-12-31 23:56:00\n2013-07-04 09:12:00\n211509\n\n\nsched_dep_time\n0\n1\n2013-01-01 05:15:00\n2013-12-31 23:59:00\n2013-07-04 09:15:00\n125557\n\n\narr_time\n0\n1\n2013-01-01 00:03:00\n2014-01-01 00:00:00\n2013-07-04 11:06:00\n220332\n\n\nsched_arr_time\n0\n1\n2013-01-01 00:05:00\n2013-12-31 23:59:00\n2013-07-04 11:20:00\n204384\n\n\n\n\n\n\n# Plot: Departure time\nggplot(flights_dt, aes(x = dep_time)) +\n  geom_histogram(binwidth = 3600, color = \"purple\", alpha = 0.7) +\n  labs(title = \"Departure Time Distribution\",\n       x = \"Departure Time\",\n       y = \"Frequency\")\n\n\n\n\n\n# Plot: Departure for each week\nflights_dt %&gt;% \n  count(week = ceiling_date(dep_time, \"week\")) %&gt;% \n  ggplot(aes(week, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Week\",\n         x = \"Week\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\n\n# Plot: Departure for each month\nflights_dt %&gt;% \n  count(month = ceiling_date(dep_time, \"month\")) %&gt;% \n  ggplot(aes(month, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Month\",\n         x = \"Month\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\nInstead of plotting the original departure time, we can round up to a nearby unit of time using ceiling_date(), and allows us to plot the number of flights per week and per month.\nReference:\n1. R for Data Science. https://r4ds.had.co.nz/dates-and-times.html\n2. How to Write Fuctions in R\n\n\n\nYes, it is useful in representing time in plots and can offer insights into patterns and/or trends over different time intervals. This can be especially true for large datasets where ceiling_date() can be used to simplify and group dates to provide a more concise and interpretable representation of trends. I don’t use this everyday, but I do think it is pretty neat!"
  },
  {
    "objectID": "function_of_the_week_ECHALUSE.html#what-is-it-for",
    "href": "function_of_the_week_ECHALUSE.html#what-is-it-for",
    "title": "lubridate::ceiling_date()",
    "section": "",
    "text": "The ceiling_date() function is part of the lubridate package. It is used for rounding a given date-time object up to the nearest boundary of a specified time unit.\nThe term  ceiling  means rounding up, and users can specify rounding up to the nearest second, minute, hour, day, week, month, or year.\n\nceiling_date(x, unit=c(\"second\", \"minute\", \"hour\", \"day\",\n    \"week\", \"month\", \"year\"))\n\n\n x  is a vector of date-time objects.\n unit  is a string, period object, or date-time object rounded to the nearest boundary of a specific time unit.\n\n\n\nExample #1\n\n\n# format: year/month/day hour/minute/second\nx &lt;- ymd_hms(\"2009-08-03 12:01:59.23\") # Monday\n\n\n# rounding\nceiling_date(x, \"second\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"minute\")\n\n[1] \"2009-08-03 12:02:00 UTC\"\n\nceiling_date(x, \"5 mins\")\n\n[1] \"2009-08-03 12:05:00 UTC\"\n\nceiling_date(x, \"hour\")\n\n[1] \"2009-08-03 13:00:00 UTC\"\n\nceiling_date(x, \"2 hours\")\n\n[1] \"2009-08-03 14:00:00 UTC\"\n\nceiling_date(x, \"day\") # Tuesday\n\n[1] \"2009-08-04 UTC\"\n\nceiling_date(x, \"week\") # Saturday\n\n[1] \"2009-08-09 UTC\"\n\nceiling_date(x, \"month\")\n\n[1] \"2009-09-01 UTC\"\n\nceiling_date(x, \"year\")\n\n[1] \"2010-01-01 UTC\"\n\n\nReference:\n1. https://lubridate.tidyverse.org/reference/round_date.html\n2. RDocumentation\n\n\nExample #2\n\n\nlibrary(nycflights13)\ndata(flights)\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\nhead(flights)\n\n# A tibble: 6 × 19\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n# To convert date and time information into a more standard datetime format.\n# We write a `function()` with parameters: year, month, day, and time.\n# Use `lubridate::make_datetime()` to create a new datetime object (make_datetime_100). \n# The time format is in HHMM and splits the time into hours (time %/% 100) and minutes (time %% 100).\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\n\n# Rows with missing departure or arrival times are filtered out. \n# Use `mutate` to create new columns:\n# departure time, arrival time, scheduled departure time, and scheduled arrival time. \n# The make_datetime_100 function is applied to, and after select columns:\n# origin, destination, columns ending with \"delay,\" and columns ending with \"time\".\n\nflights_dt &lt;- flights %&gt;% \n  filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% \n  mutate(dep_time = make_datetime_100(year, month, day, dep_time),\n         arr_time = make_datetime_100(year, month, day, arr_time),\n         sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n         sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)) %&gt;%\n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\n\n# Check\nhead(flights_dt)\n\n# A tibble: 6 × 9\n  origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n# ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt;\n\nskim(flights_dt)\n\n\nData summary\n\n\nName\nflights_dt\n\n\nNumber of rows\n328063\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\nPOSIXct\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\norigin\n0\n1\n3\n3\n0\n3\n0\n\n\ndest\n0\n1\n3\n3\n0\n104\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndep_delay\n0\n1\n12.58\n40.09\n-43\n-5\n-2\n11\n1301\n▇▁▁▁▁\n\n\narr_delay\n717\n1\n6.90\n44.63\n-86\n-17\n-5\n14\n1272\n▇▁▁▁▁\n\n\nair_time\n717\n1\n150.69\n93.69\n20\n82\n129\n192\n695\n▇▂▂▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndep_time\n0\n1\n2013-01-01 05:17:00\n2013-12-31 23:56:00\n2013-07-04 09:12:00\n211509\n\n\nsched_dep_time\n0\n1\n2013-01-01 05:15:00\n2013-12-31 23:59:00\n2013-07-04 09:15:00\n125557\n\n\narr_time\n0\n1\n2013-01-01 00:03:00\n2014-01-01 00:00:00\n2013-07-04 11:06:00\n220332\n\n\nsched_arr_time\n0\n1\n2013-01-01 00:05:00\n2013-12-31 23:59:00\n2013-07-04 11:20:00\n204384\n\n\n\n\n\n\n# Plot: Departure time\nggplot(flights_dt, aes(x = dep_time)) +\n  geom_histogram(binwidth = 3600, color = \"purple\", alpha = 0.7) +\n  labs(title = \"Departure Time Distribution\",\n       x = \"Departure Time\",\n       y = \"Frequency\")\n\n\n\n\n\n# Plot: Departure for each week\nflights_dt %&gt;% \n  count(week = ceiling_date(dep_time, \"week\")) %&gt;% \n  ggplot(aes(week, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Week\",\n         x = \"Week\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\n\n# Plot: Departure for each month\nflights_dt %&gt;% \n  count(month = ceiling_date(dep_time, \"month\")) %&gt;% \n  ggplot(aes(month, n)) +\n    geom_line(color = \"purple\") +\n    theme_minimal() +\n    labs(title = \"Flight Departure per Month\",\n         x = \"Month\",\n         y = \"Count\",\n         color = \"Line Color\")\n\n\n\n\nInstead of plotting the original departure time, we can round up to a nearby unit of time using ceiling_date(), and allows us to plot the number of flights per week and per month.\nReference:\n1. R for Data Science. https://r4ds.had.co.nz/dates-and-times.html\n2. How to Write Fuctions in R"
  },
  {
    "objectID": "function_of_the_week_ECHALUSE.html#is-it-helpful",
    "href": "function_of_the_week_ECHALUSE.html#is-it-helpful",
    "title": "lubridate::ceiling_date()",
    "section": "",
    "text": "Yes, it is useful in representing time in plots and can offer insights into patterns and/or trends over different time intervals. This can be especially true for large datasets where ceiling_date() can be used to simplify and group dates to provide a more concise and interpretable representation of trends. I don’t use this everyday, but I do think it is pretty neat!"
  },
  {
    "objectID": "function_of_the_week_McMonigal.html",
    "href": "function_of_the_week_McMonigal.html",
    "title": "n_distinct",
    "section": "",
    "text": "In this document, I will introduce the n_distinct() function from dplyr and show what it’s for.\n\n#load dplyr\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n#example dataset\ndata(starwars)\n\n\n\nThe n_distinct() function counts the number of unique values in a vector or set of vectors. It has two arguments:\n\n... : One or more vectors from your dataset.\nna.rm : Can equal TRUE or FALSE.\n\nThe default is na.rm = FALSE, meaning missing values are included in the count of distinct values by default. If TRUE, missing values will be excluded from the count of distinct values.\n\n\n\n\n#Let's see what is in our dataset.\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\n#Let's use n_distinct on a categorical variable, such as species.\nn_distinct(starwars$species)\n\n[1] 38\n\n\n\n#Let's examine how na.rm works.\nn_distinct(starwars$hair_color, na.rm = FALSE)\n\n[1] 13\n\n\n\n#Now let's change to na.rm = TRUE\nn_distinct(starwars$hair_color, na.rm = TRUE)\n\n[1] 12\n\n\n\n#Let's try with multiple vectors. Missing values will be included in the count.\nn_distinct(starwars$hair_color, starwars$eye_color)\n\n[1] 35\n\n\n\n#What are the distinct pairs?\nstarwars %&gt;% distinct(eye_color, hair_color)\n\n# A tibble: 35 × 2\n   eye_color hair_color   \n   &lt;chr&gt;     &lt;chr&gt;        \n 1 blue      blond        \n 2 yellow    &lt;NA&gt;         \n 3 red       &lt;NA&gt;         \n 4 yellow    none         \n 5 brown     brown        \n 6 blue      brown, grey  \n 7 blue      brown        \n 8 brown     black        \n 9 blue-gray auburn, white\n10 blue      auburn, grey \n# ℹ 25 more rows\n\n(tibble1 &lt;- starwars %&gt;% group_by(eye_color) %&gt;%\n  summarise(count = n_distinct(hair_color)))\n\n# A tibble: 15 × 2\n   eye_color     count\n   &lt;chr&gt;         &lt;int&gt;\n 1 black             2\n 2 blue              8\n 3 blue-gray         1\n 4 brown             4\n 5 dark              1\n 6 gold              1\n 7 green, yellow     1\n 8 hazel             2\n 9 orange            2\n10 pink              1\n11 red               2\n12 red, blue         1\n13 unknown           2\n14 white             1\n15 yellow            6\n\nsum(tibble1$count)\n\n[1] 35\n\n\n\n\n\nThe function n_distinct() is helpful for data exploration for categorical variables because it quickly counts the number of distinct values.\nHowever, n_distinct() on its own is not very powerful, and the function is more helpful when used in combination with other functions."
  },
  {
    "objectID": "function_of_the_week_McMonigal.html#what-is-it-for",
    "href": "function_of_the_week_McMonigal.html#what-is-it-for",
    "title": "n_distinct",
    "section": "",
    "text": "The n_distinct() function counts the number of unique values in a vector or set of vectors. It has two arguments:\n\n... : One or more vectors from your dataset.\nna.rm : Can equal TRUE or FALSE.\n\nThe default is na.rm = FALSE, meaning missing values are included in the count of distinct values by default. If TRUE, missing values will be excluded from the count of distinct values."
  },
  {
    "objectID": "function_of_the_week_McMonigal.html#example-using-starwars",
    "href": "function_of_the_week_McMonigal.html#example-using-starwars",
    "title": "n_distinct",
    "section": "",
    "text": "#Let's see what is in our dataset.\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       &lt;chr&gt; \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color &lt;chr&gt; \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color &lt;chr&gt; \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  &lt;chr&gt; \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        &lt;chr&gt; \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     &lt;chr&gt; \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  &lt;chr&gt; \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    &lt;chr&gt; \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      &lt;list&gt; &lt;\"The Empire Strikes Back\", \"Revenge of the Sith\", \"Return…\n$ vehicles   &lt;list&gt; &lt;\"Snowspeeder\", \"Imperial Speeder Bike\"&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, \"Imp…\n$ starships  &lt;list&gt; &lt;\"X-wing\", \"Imperial shuttle\"&gt;, &lt;&gt;, &lt;&gt;, \"TIE Advanced x1\",…\n\n\n\n#Let's use n_distinct on a categorical variable, such as species.\nn_distinct(starwars$species)\n\n[1] 38\n\n\n\n#Let's examine how na.rm works.\nn_distinct(starwars$hair_color, na.rm = FALSE)\n\n[1] 13\n\n\n\n#Now let's change to na.rm = TRUE\nn_distinct(starwars$hair_color, na.rm = TRUE)\n\n[1] 12\n\n\n\n#Let's try with multiple vectors. Missing values will be included in the count.\nn_distinct(starwars$hair_color, starwars$eye_color)\n\n[1] 35\n\n\n\n#What are the distinct pairs?\nstarwars %&gt;% distinct(eye_color, hair_color)\n\n# A tibble: 35 × 2\n   eye_color hair_color   \n   &lt;chr&gt;     &lt;chr&gt;        \n 1 blue      blond        \n 2 yellow    &lt;NA&gt;         \n 3 red       &lt;NA&gt;         \n 4 yellow    none         \n 5 brown     brown        \n 6 blue      brown, grey  \n 7 blue      brown        \n 8 brown     black        \n 9 blue-gray auburn, white\n10 blue      auburn, grey \n# ℹ 25 more rows\n\n(tibble1 &lt;- starwars %&gt;% group_by(eye_color) %&gt;%\n  summarise(count = n_distinct(hair_color)))\n\n# A tibble: 15 × 2\n   eye_color     count\n   &lt;chr&gt;         &lt;int&gt;\n 1 black             2\n 2 blue              8\n 3 blue-gray         1\n 4 brown             4\n 5 dark              1\n 6 gold              1\n 7 green, yellow     1\n 8 hazel             2\n 9 orange            2\n10 pink              1\n11 red               2\n12 red, blue         1\n13 unknown           2\n14 white             1\n15 yellow            6\n\nsum(tibble1$count)\n\n[1] 35"
  },
  {
    "objectID": "function_of_the_week_McMonigal.html#is-n_distinct-helpful",
    "href": "function_of_the_week_McMonigal.html#is-n_distinct-helpful",
    "title": "n_distinct",
    "section": "",
    "text": "The function n_distinct() is helpful for data exploration for categorical variables because it quickly counts the number of distinct values.\nHowever, n_distinct() on its own is not very powerful, and the function is more helpful when used in combination with other functions."
  },
  {
    "objectID": "presentations/function_of_the_week_CIRELL_ALFONSO.html",
    "href": "presentations/function_of_the_week_CIRELL_ALFONSO.html",
    "title": "dplyr::slice_sample",
    "section": "",
    "text": "Please sign up for a function here (Enter your name and the week you want to present): function_of_the_week_signup_2024\nFor this assignment, please submit both the .qmd and the .html files. I will add it to the website. Remove your name from the qmd if you do not wish it shared or let us know if it is okay to post in anonymously.\nMake sure to update the title, description, author, and date in the yaml above.\nPrevious years’ Functions of the Week can be found on the previous class websites:\n\nhttps://sph-r-programming-2023.netlify.app/functions/\nhttps://sph-r-programming-2022.netlify.app/functions/\nhttps://sph-r-programming.netlify.app/functions/ (2021)\n\nIf you select a function which was presented previously, please develop your own examples and content."
  },
  {
    "objectID": "presentations/function_of_the_week_CIRELL_ALFONSO.html#what-is-it-for",
    "href": "presentations/function_of_the_week_CIRELL_ALFONSO.html#what-is-it-for",
    "title": "dplyr::slice_sample",
    "section": "2.1 What is it for?",
    "text": "2.1 What is it for?\nSlice_sample( ) from the dplyr package randomly selects a row from a dataset.\n\nslice_sample(mtcars)\n\n         mpg cyl disp  hp drat   wt  qsec vs am gear carb\nValiant 18.1   6  225 105 2.76 3.46 20.22  1  0    3    1\n\n\nThere are various useful arguments in the slice_sample( ) function. We can add n to select a set number of rows.\n\nslice_sample(mtcars,n=5)\n\n                    mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMaserati Bora      15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nToyota Corona      21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nCadillac Fleetwood 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLotus Europa       30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nMerc 280C          17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n\n\nWe can also use prop if we want to sample a proportion of samples available in the data set.\n\nslice_sample(mtcars, prop=0.25)\n\n                  mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nDatsun 710       22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nPontiac Firebird 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nMazda RX4        21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nFerrari Dino     19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMerc 280C        17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nAMC Javelin      15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nHonda Civic      30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nLotus Europa     30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n\n\nThe default has it where replacement is false.\n\nslice_sample(mtcars, n=6,\n             replace= TRUE)\n\n                    mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMerc 450SE...1     16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nToyota Corona      21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nFord Pantera L...3 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFord Pantera L...4 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nMerc 280C          17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE...6     16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n\n\nLastly, we can add weight_by to add sampling weights to any non-negative vectors.\n\nslice_sample(mtcars, n=5, weight_by = wt)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4"
  },
  {
    "objectID": "presentations/function_of_the_week_CIRELL_ALFONSO.html#is-it-helpful",
    "href": "presentations/function_of_the_week_CIRELL_ALFONSO.html#is-it-helpful",
    "title": "dplyr::slice_sample",
    "section": "2.2 Is it helpful?",
    "text": "2.2 Is it helpful?\n\nThis function is definitely helpful. In larger data set, we can get a smaller random sample fairly easily."
  },
  {
    "objectID": "function_of_the_week_CIRELL_ALFONSO.html",
    "href": "function_of_the_week_CIRELL_ALFONSO.html",
    "title": "dplyr::slice_sample",
    "section": "",
    "text": "Please sign up for a function here (Enter your name and the week you want to present): function_of_the_week_signup_2024\nFor this assignment, please submit both the .qmd and the .html files. I will add it to the website. Remove your name from the qmd if you do not wish it shared or let us know if it is okay to post in anonymously.\nMake sure to update the title, description, author, and date in the yaml above.\nPrevious years’ Functions of the Week can be found on the previous class websites:\n\nhttps://sph-r-programming-2023.netlify.app/functions/\nhttps://sph-r-programming-2022.netlify.app/functions/\nhttps://sph-r-programming.netlify.app/functions/ (2021)\n\nIf you select a function which was presented previously, please develop your own examples and content."
  },
  {
    "objectID": "function_of_the_week_CIRELL_ALFONSO.html#what-is-it-for",
    "href": "function_of_the_week_CIRELL_ALFONSO.html#what-is-it-for",
    "title": "dplyr::slice_sample",
    "section": "2.1 What is it for?",
    "text": "2.1 What is it for?\nSlice_sample( ) from the dplyr package randomly selects a row from a dataset.\n\nslice_sample(mtcars)\n\n               mpg cyl  disp hp drat    wt  qsec vs am gear carb\nToyota Corona 21.5   4 120.1 97  3.7 2.465 20.01  1  0    3    1\n\n\nThere are various useful arguments in the slice_sample( ) function. We can add n to select a set number of rows.\n\nslice_sample(mtcars,n=5)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n\n\nWe can also use prop if we want to sample a proportion of samples available in the data set.\n\nslice_sample(mtcars, prop=0.25)\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n\n\nThe default has it where replacement is false.\n\nslice_sample(mtcars, n=6,\n             replace= TRUE)\n\n                    mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nHornet 4 Drive...1 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nToyota Corona      21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nPorsche 914-2      26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nCamaro Z28         13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nHornet 4 Drive...5 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nVolvo 142E         21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nLastly, we can add weight_by to add sampling weights to any non-negative vectors.\n\nslice_sample(mtcars, n=5, weight_by = wt)\n\n                     mpg cyl disp  hp drat    wt  qsec vs am gear carb\nFerrari Dino        19.7   6  145 175 3.62 2.770 15.50  0  1    5    6\nDodge Challenger    15.5   8  318 150 2.76 3.520 16.87  0  0    3    2\nLincoln Continental 10.4   8  460 215 3.00 5.424 17.82  0  0    3    4\nCadillac Fleetwood  10.4   8  472 205 2.93 5.250 17.98  0  0    3    4\nDuster 360          14.3   8  360 245 3.21 3.570 15.84  0  0    3    4"
  },
  {
    "objectID": "function_of_the_week_CIRELL_ALFONSO.html#is-it-helpful",
    "href": "function_of_the_week_CIRELL_ALFONSO.html#is-it-helpful",
    "title": "dplyr::slice_sample",
    "section": "2.2 Is it helpful?",
    "text": "2.2 Is it helpful?\n\nThis function is definitely helpful. In larger data set, we can get a smaller random sample fairly easily."
  },
  {
    "objectID": "function_of_the_week_Chapela.html",
    "href": "function_of_the_week_Chapela.html",
    "title": "Function of the Week:",
    "section": "",
    "text": "In this document, I will introduce the get_dupes() function and show what it’s for. This function is part of the janitor package so will need to load janitor first.\n\n#loading janitor\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\n\n\n\nThis function is quite simple but useful, specially when we are working with big data frames. It basically identifies duplicate rows in a given data frame.\n\n\nHere is an example to illustrate how it works:\n\n\nFirst, I will input a data frame which I will call example:\n\n\nexample &lt;- data.frame(\n  ID = c(01,02,03,04,05,06,07,08,09,10,06,12,13,07,15,16,17,06),\n  group = c(\"T\", \"T\", \"C\", \"C\", \"C\", \"T\", \"T\", \"C\", \"T\", \"C\", \"C\", \"C\", \"T\", \"T\", \"C\", \"C\",\"T\",\"C\"),\n  age = c(26, 26, 22, 25, 29, 33, 26, 32, 33, 31, 35, 32, 24, 25, 28, 20, 29, 35))\nexample\n\n   ID group age\n1   1     T  26\n2   2     T  26\n3   3     C  22\n4   4     C  25\n5   5     C  29\n6   6     T  33\n7   7     T  26\n8   8     C  32\n9   9     T  33\n10 10     C  31\n11  6     C  35\n12 12     C  32\n13 13     T  24\n14  7     T  25\n15 15     C  28\n16 16     C  20\n17 17     T  29\n18  6     C  35\n\n\n\nSince this is a small data frame, we can visually inspect it and notice that participants with ID numbers 6 and 7 are repeated. However, if our data set were larger, identifying duplicates visually would be a tedious and error-prone process.\n\n\nNow, we can use get_dupes() following this format: get_dupes (dat, ...) where:\n\n\ndat name of the data frame\n\n\n... names of the variables to search for duplicates (unquoted)\n\n\nget_dupes(example, ID)\n\n  ID dupe_count group age\n1  6          3     T  33\n2  6          3     C  35\n3  6          3     C  35\n4  7          2     T  26\n5  7          2     T  25\n\n\n\nThe output will give us the rows with duplicate records in the specified variable (ID) and a count of the duplicates (dupe_count)\n\n\nWe corroborated here that ID number 6 is repeated 3 times and ID 7 is repeated 2 times.\n\n\nWe can also use pipes with the get_dupes function:\n\n\nexample |&gt;\n  get_dupes(age)\n\n   age dupe_count ID group\n1   26          3  1     T\n2   26          3  2     T\n3   26          3  7     T\n4   25          2  4     C\n5   25          2  7     T\n6   29          2  5     C\n7   29          2 17     T\n8   32          2  8     C\n9   32          2 12     C\n10  33          2  6     T\n11  33          2  9     T\n12  35          2  6     C\n13  35          2  6     C\n\n\n\nThe output will provide us with the duplicates for age. We can observe that it will order them in descending order, with the most frequently repeated observations appearing at the top of the table. Here, we notice that age 26 is repeated 3 times, age 25 is repeated 2 times, and so forth. This results are not very informative, so we need to be careful to select a meaningful variable to account for duplicates.\n\n\nIf we don’t specify any variables, get_dupes will look for duplicates using all columns\n\n\nexample |&gt;\n  get_dupes()\n\nNo variable names specified - using all columns.\n\n\n  ID group age dupe_count\n1  6     C  35          2\n2  6     C  35          2\n\n\n\nHere, we have two rows with the exact same values in all columns.\n\n\nWe can also use tidyselect helpers. For example, we can look for duplicates among all variables except age:\n\n\nexample |&gt;\n  get_dupes(-age)\n\n  ID group dupe_count age\n1  6     C          2  35\n2  6     C          2  35\n3  7     T          2  26\n4  7     T          2  25\n\n\n\nEven though the output displays a column for age, it is not accounting for the repeated age records as it did before.\n\n\n\n\n\nYes, this function can save us a lot of time during the data cleaning process. I use it at early stages of data analysis to identify potential coding errors. For me, it is especially useful to use it before merging datasets to ensure we have only one ID code per subject."
  },
  {
    "objectID": "function_of_the_week_Chapela.html#what-is-it-for",
    "href": "function_of_the_week_Chapela.html#what-is-it-for",
    "title": "Function of the Week:",
    "section": "",
    "text": "This function is quite simple but useful, specially when we are working with big data frames. It basically identifies duplicate rows in a given data frame.\n\n\nHere is an example to illustrate how it works:\n\n\nFirst, I will input a data frame which I will call example:\n\n\nexample &lt;- data.frame(\n  ID = c(01,02,03,04,05,06,07,08,09,10,06,12,13,07,15,16,17,06),\n  group = c(\"T\", \"T\", \"C\", \"C\", \"C\", \"T\", \"T\", \"C\", \"T\", \"C\", \"C\", \"C\", \"T\", \"T\", \"C\", \"C\",\"T\",\"C\"),\n  age = c(26, 26, 22, 25, 29, 33, 26, 32, 33, 31, 35, 32, 24, 25, 28, 20, 29, 35))\nexample\n\n   ID group age\n1   1     T  26\n2   2     T  26\n3   3     C  22\n4   4     C  25\n5   5     C  29\n6   6     T  33\n7   7     T  26\n8   8     C  32\n9   9     T  33\n10 10     C  31\n11  6     C  35\n12 12     C  32\n13 13     T  24\n14  7     T  25\n15 15     C  28\n16 16     C  20\n17 17     T  29\n18  6     C  35\n\n\n\nSince this is a small data frame, we can visually inspect it and notice that participants with ID numbers 6 and 7 are repeated. However, if our data set were larger, identifying duplicates visually would be a tedious and error-prone process.\n\n\nNow, we can use get_dupes() following this format: get_dupes (dat, ...) where:\n\n\ndat name of the data frame\n\n\n... names of the variables to search for duplicates (unquoted)\n\n\nget_dupes(example, ID)\n\n  ID dupe_count group age\n1  6          3     T  33\n2  6          3     C  35\n3  6          3     C  35\n4  7          2     T  26\n5  7          2     T  25\n\n\n\nThe output will give us the rows with duplicate records in the specified variable (ID) and a count of the duplicates (dupe_count)\n\n\nWe corroborated here that ID number 6 is repeated 3 times and ID 7 is repeated 2 times.\n\n\nWe can also use pipes with the get_dupes function:\n\n\nexample |&gt;\n  get_dupes(age)\n\n   age dupe_count ID group\n1   26          3  1     T\n2   26          3  2     T\n3   26          3  7     T\n4   25          2  4     C\n5   25          2  7     T\n6   29          2  5     C\n7   29          2 17     T\n8   32          2  8     C\n9   32          2 12     C\n10  33          2  6     T\n11  33          2  9     T\n12  35          2  6     C\n13  35          2  6     C\n\n\n\nThe output will provide us with the duplicates for age. We can observe that it will order them in descending order, with the most frequently repeated observations appearing at the top of the table. Here, we notice that age 26 is repeated 3 times, age 25 is repeated 2 times, and so forth. This results are not very informative, so we need to be careful to select a meaningful variable to account for duplicates.\n\n\nIf we don’t specify any variables, get_dupes will look for duplicates using all columns\n\n\nexample |&gt;\n  get_dupes()\n\nNo variable names specified - using all columns.\n\n\n  ID group age dupe_count\n1  6     C  35          2\n2  6     C  35          2\n\n\n\nHere, we have two rows with the exact same values in all columns.\n\n\nWe can also use tidyselect helpers. For example, we can look for duplicates among all variables except age:\n\n\nexample |&gt;\n  get_dupes(-age)\n\n  ID group dupe_count age\n1  6     C          2  35\n2  6     C          2  35\n3  7     T          2  26\n4  7     T          2  25\n\n\n\nEven though the output displays a column for age, it is not accounting for the repeated age records as it did before."
  },
  {
    "objectID": "function_of_the_week_Chapela.html#is-it-helpful",
    "href": "function_of_the_week_Chapela.html#is-it-helpful",
    "title": "Function of the Week:",
    "section": "",
    "text": "Yes, this function can save us a lot of time during the data cleaning process. I use it at early stages of data analysis to identify potential coding errors. For me, it is especially useful to use it before merging datasets to ensure we have only one ID code per subject."
  },
  {
    "objectID": "function_of_the_week_Clem_write.xlsx.html",
    "href": "function_of_the_week_Clem_write.xlsx.html",
    "title": "openxlsx::write.xlsx()",
    "section": "",
    "text": "In this document, I will introduce the write.xlsx() function and show what it’s for.\n\nlibrary(openxlsx)\nlibrary(here)\n\nhere() starts at /Users/niederha/Library/CloudStorage/OneDrive-OregonHealth&ScienceUniversity/teaching/BSTA 526/BSTA_526_shared/webpage/Function_of_the_week_BSTA526_W24\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)\ndata(penguins)\n\n\n\nWrite write.xlsx() allows you to save the data frames you have created and modified as new excel sheets.\nLet’s say you want to create a separate excel sheet for a specific group. In this example we’ll take the palmerspenguins data set and make a new excel sheet with only the Adelie penguins.\n\n#filter for Adelie penguins \npenguins_adelie &lt;- penguins %&gt;%\n  filter(species == \"Adelie\")%&gt;%\n  print()\n\n# A tibble: 152 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 142 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n#save as new excel sheet\nwrite.xlsx(penguins_adelie, \n           file = \"penguins_adeile.xlsx\")\n\nThe excel file is only useful if you know where it is! You can also use write.xlsx with the here() function to help specify a specific location you would like to save the new excel file. For example I can use here() to specify that I want to save the excel file to my BSTA 526 folder so it makes it easier to find later.\n\n#to save in functions of the week folder \nwrite.xlsx(penguins_adelie, \n           file = here(\"penguins_adiele.xlsx\"))\n\nYou can also use write.xlsx to write overwrite an existing file with the overwrite argument. For example, I want to create a data frame from the palmerpenguins data set that only has Adelie penguins that live on Torgersen and overwrite our existing file we created above.\n\n#filtering for island Torgersen\npenguins_adelie_torgersen &lt;- penguins_adelie %&gt;%\n  filter(island == \"Torgersen\")%&gt;%\n  print\n\n# A tibble: 52 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 42 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n#to overwrite previous file \nwrite.xlsx(penguins_adelie_torgersen, \n           file = here(\"penguins_adiele.xlsx\"),\n           overwrite = TRUE)\n\n\n\n\nwrite.xlsx() is straightforward and helpful tool since it allows you to save excel sheets of data you have cleaned and/or modified. I could see this being extremely helpful if you need to share cleaned excel sheets of the data with other people or publishers. While it could be useful to use the overwrite argument to overwrite messy excel files this may not be in best practice."
  },
  {
    "objectID": "function_of_the_week_Clem_write.xlsx.html#what-is-it-for",
    "href": "function_of_the_week_Clem_write.xlsx.html#what-is-it-for",
    "title": "openxlsx::write.xlsx()",
    "section": "",
    "text": "Write write.xlsx() allows you to save the data frames you have created and modified as new excel sheets.\nLet’s say you want to create a separate excel sheet for a specific group. In this example we’ll take the palmerspenguins data set and make a new excel sheet with only the Adelie penguins.\n\n#filter for Adelie penguins \npenguins_adelie &lt;- penguins %&gt;%\n  filter(species == \"Adelie\")%&gt;%\n  print()\n\n# A tibble: 152 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 142 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n#save as new excel sheet\nwrite.xlsx(penguins_adelie, \n           file = \"penguins_adeile.xlsx\")\n\nThe excel file is only useful if you know where it is! You can also use write.xlsx with the here() function to help specify a specific location you would like to save the new excel file. For example I can use here() to specify that I want to save the excel file to my BSTA 526 folder so it makes it easier to find later.\n\n#to save in functions of the week folder \nwrite.xlsx(penguins_adelie, \n           file = here(\"penguins_adiele.xlsx\"))\n\nYou can also use write.xlsx to write overwrite an existing file with the overwrite argument. For example, I want to create a data frame from the palmerpenguins data set that only has Adelie penguins that live on Torgersen and overwrite our existing file we created above.\n\n#filtering for island Torgersen\npenguins_adelie_torgersen &lt;- penguins_adelie %&gt;%\n  filter(island == \"Torgersen\")%&gt;%\n  print\n\n# A tibble: 52 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 42 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n#to overwrite previous file \nwrite.xlsx(penguins_adelie_torgersen, \n           file = here(\"penguins_adiele.xlsx\"),\n           overwrite = TRUE)"
  },
  {
    "objectID": "function_of_the_week_Clem_write.xlsx.html#is-it-helpful",
    "href": "function_of_the_week_Clem_write.xlsx.html#is-it-helpful",
    "title": "openxlsx::write.xlsx()",
    "section": "",
    "text": "write.xlsx() is straightforward and helpful tool since it allows you to save excel sheets of data you have cleaned and/or modified. I could see this being extremely helpful if you need to share cleaned excel sheets of the data with other people or publishers. While it could be useful to use the overwrite argument to overwrite messy excel files this may not be in best practice."
  },
  {
    "objectID": "function_of_the_week_bsta356_Cornacchione.html",
    "href": "function_of_the_week_bsta356_Cornacchione.html",
    "title": "ggplot2::geom_map()",
    "section": "",
    "text": "In this document, I will introduce the geom_map() function and show what it’s for.\n\n# Load tidyverse up for ggplot2\nlibrary(tidyverse)\nlibrary(mapproj) \nlibrary(maps)\n\n\nThe mapproj package allows R to convert latitude and longitude coordinates into projected coordinates (you might need to install it first).\nInstalling mapproj should automatically also install the maps package, which allows you to access world map data. It’s a new version of the legacy map package mapdata, which you might still see used in example codes online.\n\n\n\nThe function geom_map() is similar to geom_bar() or geom_smooth() in the sense that it works like a predefined layout that tells the plot how to display your data. In this case, geom_map() displays polygons as a map.\n\n\n\nPolygons are closed shapes formed by connecting a series of points:\n\nThey can represent various geographical features such as countries, states, or regions. - In the context of maps, polygons define the boundaries of specific areas.\nFor example, the outline of a country on a world map is represented by a polygon. Each polygon consists of a set of coordinates (latitude and longitude) that define its shape.\n\nHere’s a visual example of a polygon using geom_map() straight out of the R documentation:\n\n\n\n\nHere we’ll walk through an example of creating a county map of Oregon:\n\nFeel free to explore each step on your own to get comfortable with the functions (they were a bit confusing for me at first!)\n\n\n# map_data() allows you to transform data from the maps package into a data frame\ncounty_map &lt;- map_data(\"county\", \"oregon\")\n\n# Rename \"region\" (state) and \"subregion\" (county) columns in county_map as state and id\nnames(county_map)[5:6] &lt;- c(\"state\", \"id\")                                \n\n# Create a new data frame with county names and id (id values are needed for mapping aesthetics)\ncountyData &lt;- data.frame(id = unique(county_map$id), value = rnorm(36)) \n\n# Now plot and develop the map\nOregonmap &lt;- ggplot(countyData) +\n  aes(map_id = id) +\n  geom_map(aes(fill = value), map = county_map, colour = \"black\") +\n  coord_map(\"polyconic\") +                                         # Choose a coordinate system* (I recommend doing a Google search)\n  expand_limits(x = county_map$long, y = county_map$lat)       +   # Setting units and adjusting the plot limits for the x and y axis\n  scale_fill_viridis_c(option=\"E\")                                 # Choose a color scale (for when you are plotting a map with actual data)\n\n# Print the map~\nprint(Oregonmap)\n\n\n\n\n\nCode partially adapted from Uwe (2013) in r - When should I use geom_map? - Stack Overflow\n\n\n\n\nIt’s a data visualization tool like any other - How useful geom_map() can be is ultimately up to you and your audience:\n\nFrom my experience, this function is a great way to include simple, yet effective maps to your reports (and student assignments!) whenever you are working with variables that are tied to regions around the world.\nAnother bonus is that it is great for beginners. geom_map() leverages the familiar code structure and building blocks of ggplot2. For those (like me!) who might be intimated by more sophisticated functions such as geom_sf() or might not have access to mapping software like ArcGIS or Tableau, geom_map() is an accessible way to learn about polygons, coordinate systems, and basic mapping of spatial data.\n\nIf you are curious or want to learn more about geom_map() check out the R documentation. To learn about geom_sf(), check out these resources:\n\nOfficial 1geom_sf()` documentation: Visualise sf objects — CoordSf • ggplot2 (tidyverse.org)\nA quick and neat tutorial for geom_sf() where you can create a proportional symbol map: Proportional symbol maps (bubble map) in ggplot2 (r-charts.com)\nGeocomputation with R by Lovelace, Nowosad, and Muenchow (an online textbook!): Geocomputation with R (bookdown.org)"
  },
  {
    "objectID": "function_of_the_week_bsta356_Cornacchione.html#what-is-it-for",
    "href": "function_of_the_week_bsta356_Cornacchione.html#what-is-it-for",
    "title": "ggplot2::geom_map()",
    "section": "",
    "text": "The function geom_map() is similar to geom_bar() or geom_smooth() in the sense that it works like a predefined layout that tells the plot how to display your data. In this case, geom_map() displays polygons as a map."
  },
  {
    "objectID": "function_of_the_week_bsta356_Cornacchione.html#but-what-are-polygons",
    "href": "function_of_the_week_bsta356_Cornacchione.html#but-what-are-polygons",
    "title": "ggplot2::geom_map()",
    "section": "",
    "text": "Polygons are closed shapes formed by connecting a series of points:\n\nThey can represent various geographical features such as countries, states, or regions. - In the context of maps, polygons define the boundaries of specific areas.\nFor example, the outline of a country on a world map is represented by a polygon. Each polygon consists of a set of coordinates (latitude and longitude) that define its shape.\n\nHere’s a visual example of a polygon using geom_map() straight out of the R documentation:"
  },
  {
    "objectID": "function_of_the_week_bsta356_Cornacchione.html#displaying-polygons-as-a-map",
    "href": "function_of_the_week_bsta356_Cornacchione.html#displaying-polygons-as-a-map",
    "title": "ggplot2::geom_map()",
    "section": "",
    "text": "Here we’ll walk through an example of creating a county map of Oregon:\n\nFeel free to explore each step on your own to get comfortable with the functions (they were a bit confusing for me at first!)\n\n\n# map_data() allows you to transform data from the maps package into a data frame\ncounty_map &lt;- map_data(\"county\", \"oregon\")\n\n# Rename \"region\" (state) and \"subregion\" (county) columns in county_map as state and id\nnames(county_map)[5:6] &lt;- c(\"state\", \"id\")                                \n\n# Create a new data frame with county names and id (id values are needed for mapping aesthetics)\ncountyData &lt;- data.frame(id = unique(county_map$id), value = rnorm(36)) \n\n# Now plot and develop the map\nOregonmap &lt;- ggplot(countyData) +\n  aes(map_id = id) +\n  geom_map(aes(fill = value), map = county_map, colour = \"black\") +\n  coord_map(\"polyconic\") +                                         # Choose a coordinate system* (I recommend doing a Google search)\n  expand_limits(x = county_map$long, y = county_map$lat)       +   # Setting units and adjusting the plot limits for the x and y axis\n  scale_fill_viridis_c(option=\"E\")                                 # Choose a color scale (for when you are plotting a map with actual data)\n\n# Print the map~\nprint(Oregonmap)\n\n\n\n\n\nCode partially adapted from Uwe (2013) in r - When should I use geom_map? - Stack Overflow"
  },
  {
    "objectID": "function_of_the_week_bsta356_Cornacchione.html#is-it-helpful",
    "href": "function_of_the_week_bsta356_Cornacchione.html#is-it-helpful",
    "title": "ggplot2::geom_map()",
    "section": "",
    "text": "It’s a data visualization tool like any other - How useful geom_map() can be is ultimately up to you and your audience:\n\nFrom my experience, this function is a great way to include simple, yet effective maps to your reports (and student assignments!) whenever you are working with variables that are tied to regions around the world.\nAnother bonus is that it is great for beginners. geom_map() leverages the familiar code structure and building blocks of ggplot2. For those (like me!) who might be intimated by more sophisticated functions such as geom_sf() or might not have access to mapping software like ArcGIS or Tableau, geom_map() is an accessible way to learn about polygons, coordinate systems, and basic mapping of spatial data.\n\nIf you are curious or want to learn more about geom_map() check out the R documentation. To learn about geom_sf(), check out these resources:\n\nOfficial 1geom_sf()` documentation: Visualise sf objects — CoordSf • ggplot2 (tidyverse.org)\nA quick and neat tutorial for geom_sf() where you can create a proportional symbol map: Proportional symbol maps (bubble map) in ggplot2 (r-charts.com)\nGeocomputation with R by Lovelace, Nowosad, and Muenchow (an online textbook!): Geocomputation with R (bookdown.org)"
  },
  {
    "objectID": "function_of_the_week_Cristancho.html",
    "href": "function_of_the_week_Cristancho.html",
    "title": "tidyr::uncount()",
    "section": "",
    "text": "Duplicate rows according to a weighting variable.\nPerforms the opposite operation to dplyr::count(), duplicating rows according to a weighting variable (or expression). Therefore, expand counts into multiple rows.\n\nUsage: uncount(data, weights, ..., .remove = TRUE, .id = NULL)\n\n\nArguments\n\n\ndata\nA data frame, tibble, or grouped tibble.\nweights (integer)\nA vector of weights. Evaluated in the context of data; supports quasi-quotation.\n.remove\nIf TRUE, and “weights” is the name of a column in the data, then this column is removed.\n.id\nSupply a string to create a new variable which gives a unique identifier for each created row.\n… Additional arguments passed on to methods.\n\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\nuncount (penguins, 2) #duplicate the rows\n\n# A tibble: 688 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.1          18.7               181        3750\n 3 Adelie  Torgersen           39.5          17.4               186        3800\n 4 Adelie  Torgersen           39.5          17.4               186        3800\n 5 Adelie  Torgersen           40.3          18                 195        3250\n 6 Adelie  Torgersen           40.3          18                 195        3250\n 7 Adelie  Torgersen           NA            NA                  NA          NA\n 8 Adelie  Torgersen           NA            NA                  NA          NA\n 9 Adelie  Torgersen           36.7          19.3               193        3450\n10 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 678 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\nuncount (penguins, 1, .id = \"id\") # adding consecutive ID\n\n# A tibble: 344 × 9\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 3 more variables: sex &lt;fct&gt;, year &lt;int&gt;, id &lt;int&gt;\n\n# uncount (penguins$island, 1, .id = \"id\"): error!\n\n\nisland &lt;- penguins %&gt;% distinct (island)\nisland %&gt;% gt()\n\n\n\n\n\n  \n    \n    \n      island\n    \n  \n  \n    Torgersen\n    Biscoe\n    Dream\n  \n  \n  \n\n\n\nnew_island &lt;- uncount (island,3)\nnew_island %&gt;% group_by(island) %&gt;%  count() %&gt;% gt ()\n\n\n\n\n\n  \n    \n    \n      n\n    \n  \n  \n    \n      Biscoe\n    \n    3\n    \n      Dream\n    \n    3\n    \n      Torgersen\n    \n    3\n  \n  \n  \n\n\n\n\nIf you have a data frame with a column representing the number in each group (frequency table), and you want to create a new data frame “unfolding” this table, with each row representing a single observation. Replicate each row based on the number in that group.\n\ntable_1 &lt;- penguins %&gt;% count (island)\ntable_1 %&gt;% gt() \n\n\n\n\n\n  \n    \n    \n      island\n      n\n    \n  \n  \n    Biscoe\n168\n    Dream\n124\n    Torgersen\n52\n  \n  \n  \n\n\n\nduplicate_p &lt;- uncount (table_1, n, .id = \"id\")\nglimpse(duplicate_p) #`only 2 columns`\n\nRows: 344\nColumns: 2\n$ island &lt;fct&gt; Biscoe, Biscoe, Biscoe, Biscoe, Biscoe, Biscoe, Biscoe, Biscoe,…\n$ id     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n\npenguins &lt;- penguins %&gt;% arrange(island)\nall(penguins$island == duplicate_p$island) \n\n[1] TRUE\n\n\n\n\n\n\n\nMultiplicate rows according to a key and weigth, or created a consecutive ID.\n\n\nThis can be useful for tasks like expanding data to represent individual occurrences within a group or category."
  },
  {
    "objectID": "function_of_the_week_Cristancho.html#what-is-it-for",
    "href": "function_of_the_week_Cristancho.html#what-is-it-for",
    "title": "tidyr::uncount()",
    "section": "",
    "text": "Duplicate rows according to a weighting variable.\nPerforms the opposite operation to dplyr::count(), duplicating rows according to a weighting variable (or expression). Therefore, expand counts into multiple rows.\n\nUsage: uncount(data, weights, ..., .remove = TRUE, .id = NULL)\n\n\nArguments\n\n\ndata\nA data frame, tibble, or grouped tibble.\nweights (integer)\nA vector of weights. Evaluated in the context of data; supports quasi-quotation.\n.remove\nIf TRUE, and “weights” is the name of a column in the data, then this column is removed.\n.id\nSupply a string to create a new variable which gives a unique identifier for each created row.\n… Additional arguments passed on to methods.\n\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\nuncount (penguins, 2) #duplicate the rows\n\n# A tibble: 688 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.1          18.7               181        3750\n 3 Adelie  Torgersen           39.5          17.4               186        3800\n 4 Adelie  Torgersen           39.5          17.4               186        3800\n 5 Adelie  Torgersen           40.3          18                 195        3250\n 6 Adelie  Torgersen           40.3          18                 195        3250\n 7 Adelie  Torgersen           NA            NA                  NA          NA\n 8 Adelie  Torgersen           NA            NA                  NA          NA\n 9 Adelie  Torgersen           36.7          19.3               193        3450\n10 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 678 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\nuncount (penguins, 1, .id = \"id\") # adding consecutive ID\n\n# A tibble: 344 × 9\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 3 more variables: sex &lt;fct&gt;, year &lt;int&gt;, id &lt;int&gt;\n\n# uncount (penguins$island, 1, .id = \"id\"): error!\n\n\nisland &lt;- penguins %&gt;% distinct (island)\nisland %&gt;% gt()\n\n\n\n\n\n  \n    \n    \n      island\n    \n  \n  \n    Torgersen\n    Biscoe\n    Dream\n  \n  \n  \n\n\n\nnew_island &lt;- uncount (island,3)\nnew_island %&gt;% group_by(island) %&gt;%  count() %&gt;% gt ()\n\n\n\n\n\n  \n    \n    \n      n\n    \n  \n  \n    \n      Biscoe\n    \n    3\n    \n      Dream\n    \n    3\n    \n      Torgersen\n    \n    3\n  \n  \n  \n\n\n\n\nIf you have a data frame with a column representing the number in each group (frequency table), and you want to create a new data frame “unfolding” this table, with each row representing a single observation. Replicate each row based on the number in that group.\n\ntable_1 &lt;- penguins %&gt;% count (island)\ntable_1 %&gt;% gt() \n\n\n\n\n\n  \n    \n    \n      island\n      n\n    \n  \n  \n    Biscoe\n168\n    Dream\n124\n    Torgersen\n52\n  \n  \n  \n\n\n\nduplicate_p &lt;- uncount (table_1, n, .id = \"id\")\nglimpse(duplicate_p) #`only 2 columns`\n\nRows: 344\nColumns: 2\n$ island &lt;fct&gt; Biscoe, Biscoe, Biscoe, Biscoe, Biscoe, Biscoe, Biscoe, Biscoe,…\n$ id     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n\npenguins &lt;- penguins %&gt;% arrange(island)\nall(penguins$island == duplicate_p$island) \n\n[1] TRUE"
  },
  {
    "objectID": "function_of_the_week_Cristancho.html#is-it-helpful",
    "href": "function_of_the_week_Cristancho.html#is-it-helpful",
    "title": "tidyr::uncount()",
    "section": "",
    "text": "Multiplicate rows according to a key and weigth, or created a consecutive ID.\n\n\nThis can be useful for tasks like expanding data to represent individual occurrences within a group or category."
  },
  {
    "objectID": "function_of_the_week_Delsey_str_match_presentation.html",
    "href": "function_of_the_week_Delsey_str_match_presentation.html",
    "title": "stringr::str-match",
    "section": "",
    "text": "In this document, I will introduce the str_match function and show what it’s for.\n\n#load tidyverse up\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n#example dataset\nlibrary(palmerpenguins)\ndata(penguins)\n\n\n\nThe function str_match takes a character vector and a regex pattern and returns the first time that the pattern appears in each element of the vector. Specifically str_match will return a matrix of all of the matches. We will get to what that means later.\nTo explain this let’s remind ourselves what a character vector is:\n\ncharacter_vector &lt;- c(\"This\", \"is an\", \"example\")\ntypeof(character_vector)\n\n[1] \"character\"\n\n\nNext we need to know a few regular expression (regex) special characters. There are quite a number of them so I will just define the ones I will be using here:\n\"\" regular expressions will be placed inside of quotation marks.\n\"[Aa]\" This will match with either an upper case or lower case \"A\".\n\"A\" this will only match an upper case \"A\".\n\"A+\" this will match with an A followed by any number of repeated A's \n\"[A-Za-z]\" will match with any letter upper or lower case\n\".\" will match with any character\n\"^a\" will match with any a at the start of the string\n\"a$\" will match with any a at the end of the string\nHere is the data we will be working with\n\nwords_df &lt;- as_tibble(words)\nsentences_vec &lt;- sentences\n\nwords %&gt;% head(20)\n\n [1] \"a\"         \"able\"      \"about\"     \"absolute\"  \"accept\"    \"account\"  \n [7] \"achieve\"   \"across\"    \"act\"       \"active\"    \"actual\"    \"add\"      \n[13] \"address\"   \"admit\"     \"advertise\" \"affect\"    \"afford\"    \"after\"    \n[19] \"afternoon\" \"again\"    \n\nhead(sentences_vec)\n\n[1] \"The birch canoe slid on the smooth planks.\" \n[2] \"Glue the sheet to the dark blue background.\"\n[3] \"It's easy to tell the depth of a well.\"     \n[4] \"These days a chicken leg is a rare dish.\"   \n[5] \"Rice is often served in round bowls.\"       \n[6] \"The juice of lemons makes fine punch.\"      \n\nlength(words)\n\n[1] 980\n\n\nLets try to collect every observation in sentences_vec that contains the letters “th”\n\n# we can see that it returns only the matched portion\nstr_match(sentences_vec, \"th\")\n\n       [,1]\n  [1,] \"th\"\n  [2,] \"th\"\n  [3,] \"th\"\n  [4,] NA  \n  [5,] NA  \n  [6,] NA  \n  [7,] \"th\"\n  [8,] NA  \n  [9,] NA  \n [10,] NA  \n [11,] \"th\"\n [12,] NA  \n [13,] \"th\"\n [14,] \"th\"\n [15,] \"th\"\n [16,] \"th\"\n [17,] NA  \n [18,] \"th\"\n [19,] \"th\"\n [20,] \"th\"\n [ reached getOption(\"max.print\") -- omitted 700 rows ]\n\n# if we want the whole string that contains the th we can add a few more operators\n\n# adding the . operator looks for a th between any other characters\nstr_match(sentences_vec, \".th.\")\n\n       [,1]  \n  [1,] \" the\"\n  [2,] \" the\"\n  [3,] \" the\"\n  [4,] NA    \n  [5,] NA    \n  [6,] NA    \n  [7,] \" thr\"\n  [8,] NA    \n  [9,] NA    \n [10,] NA    \n [11,] \" the\"\n [12,] NA    \n [13,] \" the\"\n [14,] \" the\"\n [15,] \" the\"\n [16,] \" the\"\n [17,] NA    \n [18,] \" the\"\n [19,] \" the\"\n [20,] \" the\"\n [ reached getOption(\"max.print\") -- omitted 700 rows ]\n\n# and if we finally add the + we will get the entire string\nstr_match(sentences_vec, \".+th.+\")\n\n       [,1]                                                       \n  [1,] \"The birch canoe slid on the smooth planks.\"               \n  [2,] \"Glue the sheet to the dark blue background.\"              \n  [3,] \"It's easy to tell the depth of a well.\"                   \n  [4,] NA                                                         \n  [5,] NA                                                         \n  [6,] NA                                                         \n  [7,] \"The box was thrown beside the parked truck.\"              \n  [8,] NA                                                         \n  [9,] NA                                                         \n [10,] NA                                                         \n [11,] \"The boy was there when the sun rose.\"                     \n [12,] NA                                                         \n [13,] \"The source of the huge river is the clear spring.\"        \n [14,] \"Kick the ball straight and follow through.\"               \n [15,] \"Help the woman get back to her feet.\"                     \n [16,] \"A pot of tea helps to pass the evening.\"                  \n [17,] NA                                                         \n [18,] \"The soft cushion broke the man's fall.\"                   \n [19,] \"The salt breeze came across from the sea.\"                \n [20,] \"The girl at the booth sold fifty bonds.\"                  \n [ reached getOption(\"max.print\") -- omitted 700 rows ]\n\n\n\n\n\n\n# recall that words_df is a tibble rather than a vector \n\n# here we see that str_match does not like recieving an entire data frame\n# even if that data frame only contains one column\n\nwords_df %&gt;% \n  str_match(\".+th.+\")\n\nWarning in stri_match_first_regex(string, pattern, opts_regex = opts(pattern)):\nargument is not an atomic vector; coercing\n\n\n     [,1]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n[1,] \"c(\\\"a\\\", \\\"able\\\", \\\"about\\\", \\\"absolute\\\", \\\"accept\\\", \\\"account\\\", \\\"achieve\\\", \\\"across\\\", \\\"act\\\", \\\"active\\\", \\\"actual\\\", \\\"add\\\", \\\"address\\\", \\\"admit\\\", \\\"advertise\\\", \\\"affect\\\", \\\"afford\\\", \\\"after\\\", \\\"afternoon\\\", \\\"again\\\", \\\"against\\\", \\\"age\\\", \\\"agent\\\", \\\"ago\\\", \\\"agree\\\", \\\"air\\\", \\\"all\\\", \\\"allow\\\", \\\"almost\\\", \\\"along\\\", \\\"already\\\", \\\"alright\\\", \\\"also\\\", \\\"although\\\", \\\"always\\\", \\\"america\\\", \\\"amount\\\", \\\"and\\\", \\\"another\\\", \\\"answer\\\", \\\"any\\\", \\\"apart\\\", \\\"apparent\\\", \\\"appear\\\", \\\"apply\\\", \\\"appoint\\\", \\\"approach\\\", \\\"appropriate\\\", \\\"area\\\", \\\"argue\\\", \\\"arm\\\", \\\"around\\\", \"\n\n\n\n# and now it will work fine\nwords_df$value %&gt;% \n  str_match(\".+th.+\")\n\n       [,1]       \n  [1,] NA         \n  [2,] NA         \n  [3,] NA         \n  [4,] NA         \n  [5,] NA         \n  [6,] NA         \n  [7,] NA         \n  [8,] NA         \n  [9,] NA         \n [10,] NA         \n [11,] NA         \n [12,] NA         \n [13,] NA         \n [14,] NA         \n [15,] NA         \n [16,] NA         \n [17,] NA         \n [18,] NA         \n [19,] NA         \n [20,] NA         \n [ reached getOption(\"max.print\") -- omitted 960 rows ]\n\n\nAnother problem you might encounter\n\n# Notice how the column name is not what I asked it to be\n\nwords_df %&gt;% \n  mutate(the = str_match(value, \".+the.+\")) %&gt;% \n  drop_na(the)\n\n# A tibble: 12 × 2\n   value     the[,1]  \n   &lt;chr&gt;     &lt;chr&gt;    \n 1 another   another  \n 2 bother    bother   \n 3 brother   brother  \n 4 either    either   \n 5 father    father   \n 6 further   further  \n 7 mother    mother   \n 8 other     other    \n 9 otherwise otherwise\n10 rather    rather   \n11 together  together \n12 whether   whether  \n\n\nThis is because the output of str_match is a matrix. In this case we have a matrix with only a single vector in it so it works to make the new column but the name is all messed up.\nTo fix this issue we should just use str_extract which is a very closely related function that returns a vector of matches rather than a matrix\n\n# and we can see this fixes the issue\n\nwords_df %&gt;% \n  mutate(the = str_extract(value, \".+the.+\")) %&gt;% \n  drop_na(the)\n\n# A tibble: 12 × 2\n   value     the      \n   &lt;chr&gt;     &lt;chr&gt;    \n 1 another   another  \n 2 bother    bother   \n 3 brother   brother  \n 4 either    either   \n 5 father    father   \n 6 further   further  \n 7 mother    mother   \n 8 other     other    \n 9 otherwise otherwise\n10 rather    rather   \n11 together  together \n12 whether   whether  \n\n\n\n\n\nstr_match returns a matrix because it is possible for a regex to return multiple different groups of characters. We won’t go into regex groups because it can get fairly complicated but here is an example of what the output would look like.\n\n# Here I asked str_match to split the match into two groups and it assigned each one a column in the matrix\n\npenguins_raw$studyName %&gt;% \n  str_match(\"([A-Z]+)(\\\\d+)\")\n\n       [,1]      [,2]  [,3]  \n  [1,] \"PAL0708\" \"PAL\" \"0708\"\n  [2,] \"PAL0708\" \"PAL\" \"0708\"\n  [3,] \"PAL0708\" \"PAL\" \"0708\"\n  [4,] \"PAL0708\" \"PAL\" \"0708\"\n  [5,] \"PAL0708\" \"PAL\" \"0708\"\n  [6,] \"PAL0708\" \"PAL\" \"0708\"\n [ reached getOption(\"max.print\") -- omitted 338 rows ]\n\n\n\n\n\nFinally we have str_match_all which returns every time the pattern is matched rather than just the first time in an observation.\n\nstr_match_all(sentences, \".t.\")[1]\n\n[[1]]\n     [,1] \n[1,] \" th\"\n[2,] \"oth\"\n\n# compare this with\n\nstr_match(sentences, \".t.\")[1]\n\n[1] \" th\"\n\n# now lets see the difference in the sentence\n\nsentences[1]\n\n[1] \"The birch canoe slid on the smooth planks.\"\n\n\n\n\n\n\nDiscuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\n\nYes, I believe it is very helpful but I also must admit it can feel very finicky to use. First you need to get the regex right. Then you need to deal with the output and input not always working nicely with dplyr.\nI believe one of the big uses for str_match is for finding things like phone numbers in large character vectors.\nHere is what I think may be a more real world usage of str_match:\n\npenguins_raw %&gt;% \n  select(Comments)\n\n# A tibble: 344 × 1\n   Comments                             \n   &lt;chr&gt;                                \n 1 Not enough blood for isotopes.       \n 2 &lt;NA&gt;                                 \n 3 &lt;NA&gt;                                 \n 4 Adult not sampled.                   \n 5 &lt;NA&gt;                                 \n 6 &lt;NA&gt;                                 \n 7 Nest never observed with full clutch.\n 8 Nest never observed with full clutch.\n 9 No blood sample obtained.            \n10 No blood sample obtained for sexing. \n# ℹ 334 more rows\n\n# Looking at the penguin_raw data there is a comments variable. If I were to want to find all observations that included a comment referencing a nest I could do so like this:\n\npenguins_raw %&gt;%  \n  mutate(match = str_match(Comments, pattern = \".*[Nn]est.*\")) %&gt;% \n  filter(!is.na(match)) %&gt;% \n  select(match, everything())\n\nWarning: Using one column matrices in `filter()` was deprecated in dplyr 1.1.0.\nℹ Please use one dimensional logical vectors instead.\n\n\n# A tibble: 36 × 18\n   match[,1]               studyName `Sample Number` Species Region Island Stage\n   &lt;chr&gt;                   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;\n 1 Nest never observed wi… PAL0708                 7 Adelie… Anvers Torge… Adul…\n 2 Nest never observed wi… PAL0708                 8 Adelie… Anvers Torge… Adul…\n 3 Nest never observed wi… PAL0708                29 Adelie… Anvers Biscoe Adul…\n 4 Nest never observed wi… PAL0708                30 Adelie… Anvers Biscoe Adul…\n 5 Nest never observed wi… PAL0708                39 Adelie… Anvers Dream  Adul…\n 6 Nest never observed wi… PAL0708                40 Adelie… Anvers Dream  Adul…\n 7 Nest never observed wi… PAL0809                69 Adelie… Anvers Torge… Adul…\n 8 Nest never observed wi… PAL0809                70 Adelie… Anvers Torge… Adul…\n 9 Nest never observed wi… PAL0910               121 Adelie… Anvers Torge… Adul…\n10 Nest never observed wi… PAL0910               122 Adelie… Anvers Torge… Adul…\n# ℹ 26 more rows\n# ℹ 11 more variables: `Individual ID` &lt;chr&gt;, `Clutch Completion` &lt;chr&gt;,\n#   `Date Egg` &lt;date&gt;, `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;"
  },
  {
    "objectID": "function_of_the_week_Delsey_str_match_presentation.html#what-is-it-for",
    "href": "function_of_the_week_Delsey_str_match_presentation.html#what-is-it-for",
    "title": "stringr::str-match",
    "section": "",
    "text": "The function str_match takes a character vector and a regex pattern and returns the first time that the pattern appears in each element of the vector. Specifically str_match will return a matrix of all of the matches. We will get to what that means later.\nTo explain this let’s remind ourselves what a character vector is:\n\ncharacter_vector &lt;- c(\"This\", \"is an\", \"example\")\ntypeof(character_vector)\n\n[1] \"character\"\n\n\nNext we need to know a few regular expression (regex) special characters. There are quite a number of them so I will just define the ones I will be using here:\n\"\" regular expressions will be placed inside of quotation marks.\n\"[Aa]\" This will match with either an upper case or lower case \"A\".\n\"A\" this will only match an upper case \"A\".\n\"A+\" this will match with an A followed by any number of repeated A's \n\"[A-Za-z]\" will match with any letter upper or lower case\n\".\" will match with any character\n\"^a\" will match with any a at the start of the string\n\"a$\" will match with any a at the end of the string\nHere is the data we will be working with\n\nwords_df &lt;- as_tibble(words)\nsentences_vec &lt;- sentences\n\nwords %&gt;% head(20)\n\n [1] \"a\"         \"able\"      \"about\"     \"absolute\"  \"accept\"    \"account\"  \n [7] \"achieve\"   \"across\"    \"act\"       \"active\"    \"actual\"    \"add\"      \n[13] \"address\"   \"admit\"     \"advertise\" \"affect\"    \"afford\"    \"after\"    \n[19] \"afternoon\" \"again\"    \n\nhead(sentences_vec)\n\n[1] \"The birch canoe slid on the smooth planks.\" \n[2] \"Glue the sheet to the dark blue background.\"\n[3] \"It's easy to tell the depth of a well.\"     \n[4] \"These days a chicken leg is a rare dish.\"   \n[5] \"Rice is often served in round bowls.\"       \n[6] \"The juice of lemons makes fine punch.\"      \n\nlength(words)\n\n[1] 980\n\n\nLets try to collect every observation in sentences_vec that contains the letters “th”\n\n# we can see that it returns only the matched portion\nstr_match(sentences_vec, \"th\")\n\n       [,1]\n  [1,] \"th\"\n  [2,] \"th\"\n  [3,] \"th\"\n  [4,] NA  \n  [5,] NA  \n  [6,] NA  \n  [7,] \"th\"\n  [8,] NA  \n  [9,] NA  \n [10,] NA  \n [11,] \"th\"\n [12,] NA  \n [13,] \"th\"\n [14,] \"th\"\n [15,] \"th\"\n [16,] \"th\"\n [17,] NA  \n [18,] \"th\"\n [19,] \"th\"\n [20,] \"th\"\n [ reached getOption(\"max.print\") -- omitted 700 rows ]\n\n# if we want the whole string that contains the th we can add a few more operators\n\n# adding the . operator looks for a th between any other characters\nstr_match(sentences_vec, \".th.\")\n\n       [,1]  \n  [1,] \" the\"\n  [2,] \" the\"\n  [3,] \" the\"\n  [4,] NA    \n  [5,] NA    \n  [6,] NA    \n  [7,] \" thr\"\n  [8,] NA    \n  [9,] NA    \n [10,] NA    \n [11,] \" the\"\n [12,] NA    \n [13,] \" the\"\n [14,] \" the\"\n [15,] \" the\"\n [16,] \" the\"\n [17,] NA    \n [18,] \" the\"\n [19,] \" the\"\n [20,] \" the\"\n [ reached getOption(\"max.print\") -- omitted 700 rows ]\n\n# and if we finally add the + we will get the entire string\nstr_match(sentences_vec, \".+th.+\")\n\n       [,1]                                                       \n  [1,] \"The birch canoe slid on the smooth planks.\"               \n  [2,] \"Glue the sheet to the dark blue background.\"              \n  [3,] \"It's easy to tell the depth of a well.\"                   \n  [4,] NA                                                         \n  [5,] NA                                                         \n  [6,] NA                                                         \n  [7,] \"The box was thrown beside the parked truck.\"              \n  [8,] NA                                                         \n  [9,] NA                                                         \n [10,] NA                                                         \n [11,] \"The boy was there when the sun rose.\"                     \n [12,] NA                                                         \n [13,] \"The source of the huge river is the clear spring.\"        \n [14,] \"Kick the ball straight and follow through.\"               \n [15,] \"Help the woman get back to her feet.\"                     \n [16,] \"A pot of tea helps to pass the evening.\"                  \n [17,] NA                                                         \n [18,] \"The soft cushion broke the man's fall.\"                   \n [19,] \"The salt breeze came across from the sea.\"                \n [20,] \"The girl at the booth sold fifty bonds.\"                  \n [ reached getOption(\"max.print\") -- omitted 700 rows ]"
  },
  {
    "objectID": "function_of_the_week_Delsey_str_match_presentation.html#lets-look-at-some-complications-with-str_match",
    "href": "function_of_the_week_Delsey_str_match_presentation.html#lets-look-at-some-complications-with-str_match",
    "title": "stringr::str-match",
    "section": "",
    "text": "# recall that words_df is a tibble rather than a vector \n\n# here we see that str_match does not like recieving an entire data frame\n# even if that data frame only contains one column\n\nwords_df %&gt;% \n  str_match(\".+th.+\")\n\nWarning in stri_match_first_regex(string, pattern, opts_regex = opts(pattern)):\nargument is not an atomic vector; coercing\n\n\n     [,1]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n[1,] \"c(\\\"a\\\", \\\"able\\\", \\\"about\\\", \\\"absolute\\\", \\\"accept\\\", \\\"account\\\", \\\"achieve\\\", \\\"across\\\", \\\"act\\\", \\\"active\\\", \\\"actual\\\", \\\"add\\\", \\\"address\\\", \\\"admit\\\", \\\"advertise\\\", \\\"affect\\\", \\\"afford\\\", \\\"after\\\", \\\"afternoon\\\", \\\"again\\\", \\\"against\\\", \\\"age\\\", \\\"agent\\\", \\\"ago\\\", \\\"agree\\\", \\\"air\\\", \\\"all\\\", \\\"allow\\\", \\\"almost\\\", \\\"along\\\", \\\"already\\\", \\\"alright\\\", \\\"also\\\", \\\"although\\\", \\\"always\\\", \\\"america\\\", \\\"amount\\\", \\\"and\\\", \\\"another\\\", \\\"answer\\\", \\\"any\\\", \\\"apart\\\", \\\"apparent\\\", \\\"appear\\\", \\\"apply\\\", \\\"appoint\\\", \\\"approach\\\", \\\"appropriate\\\", \\\"area\\\", \\\"argue\\\", \\\"arm\\\", \\\"around\\\", \"\n\n\n\n# and now it will work fine\nwords_df$value %&gt;% \n  str_match(\".+th.+\")\n\n       [,1]       \n  [1,] NA         \n  [2,] NA         \n  [3,] NA         \n  [4,] NA         \n  [5,] NA         \n  [6,] NA         \n  [7,] NA         \n  [8,] NA         \n  [9,] NA         \n [10,] NA         \n [11,] NA         \n [12,] NA         \n [13,] NA         \n [14,] NA         \n [15,] NA         \n [16,] NA         \n [17,] NA         \n [18,] NA         \n [19,] NA         \n [20,] NA         \n [ reached getOption(\"max.print\") -- omitted 960 rows ]\n\n\nAnother problem you might encounter\n\n# Notice how the column name is not what I asked it to be\n\nwords_df %&gt;% \n  mutate(the = str_match(value, \".+the.+\")) %&gt;% \n  drop_na(the)\n\n# A tibble: 12 × 2\n   value     the[,1]  \n   &lt;chr&gt;     &lt;chr&gt;    \n 1 another   another  \n 2 bother    bother   \n 3 brother   brother  \n 4 either    either   \n 5 father    father   \n 6 further   further  \n 7 mother    mother   \n 8 other     other    \n 9 otherwise otherwise\n10 rather    rather   \n11 together  together \n12 whether   whether  \n\n\nThis is because the output of str_match is a matrix. In this case we have a matrix with only a single vector in it so it works to make the new column but the name is all messed up.\nTo fix this issue we should just use str_extract which is a very closely related function that returns a vector of matches rather than a matrix\n\n# and we can see this fixes the issue\n\nwords_df %&gt;% \n  mutate(the = str_extract(value, \".+the.+\")) %&gt;% \n  drop_na(the)\n\n# A tibble: 12 × 2\n   value     the      \n   &lt;chr&gt;     &lt;chr&gt;    \n 1 another   another  \n 2 bother    bother   \n 3 brother   brother  \n 4 either    either   \n 5 father    father   \n 6 further   further  \n 7 mother    mother   \n 8 other     other    \n 9 otherwise otherwise\n10 rather    rather   \n11 together  together \n12 whether   whether"
  },
  {
    "objectID": "function_of_the_week_Delsey_str_match_presentation.html#so-why-does-str_match-return-a-matrix-at-all",
    "href": "function_of_the_week_Delsey_str_match_presentation.html#so-why-does-str_match-return-a-matrix-at-all",
    "title": "stringr::str-match",
    "section": "",
    "text": "str_match returns a matrix because it is possible for a regex to return multiple different groups of characters. We won’t go into regex groups because it can get fairly complicated but here is an example of what the output would look like.\n\n# Here I asked str_match to split the match into two groups and it assigned each one a column in the matrix\n\npenguins_raw$studyName %&gt;% \n  str_match(\"([A-Z]+)(\\\\d+)\")\n\n       [,1]      [,2]  [,3]  \n  [1,] \"PAL0708\" \"PAL\" \"0708\"\n  [2,] \"PAL0708\" \"PAL\" \"0708\"\n  [3,] \"PAL0708\" \"PAL\" \"0708\"\n  [4,] \"PAL0708\" \"PAL\" \"0708\"\n  [5,] \"PAL0708\" \"PAL\" \"0708\"\n  [6,] \"PAL0708\" \"PAL\" \"0708\"\n [ reached getOption(\"max.print\") -- omitted 338 rows ]"
  },
  {
    "objectID": "function_of_the_week_Delsey_str_match_presentation.html#str_match_all",
    "href": "function_of_the_week_Delsey_str_match_presentation.html#str_match_all",
    "title": "stringr::str-match",
    "section": "",
    "text": "Finally we have str_match_all which returns every time the pattern is matched rather than just the first time in an observation.\n\nstr_match_all(sentences, \".t.\")[1]\n\n[[1]]\n     [,1] \n[1,] \" th\"\n[2,] \"oth\"\n\n# compare this with\n\nstr_match(sentences, \".t.\")[1]\n\n[1] \" th\"\n\n# now lets see the difference in the sentence\n\nsentences[1]\n\n[1] \"The birch canoe slid on the smooth planks.\""
  },
  {
    "objectID": "function_of_the_week_Delsey_str_match_presentation.html#is-it-helpful",
    "href": "function_of_the_week_Delsey_str_match_presentation.html#is-it-helpful",
    "title": "stringr::str-match",
    "section": "",
    "text": "Discuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\n\nYes, I believe it is very helpful but I also must admit it can feel very finicky to use. First you need to get the regex right. Then you need to deal with the output and input not always working nicely with dplyr.\nI believe one of the big uses for str_match is for finding things like phone numbers in large character vectors.\nHere is what I think may be a more real world usage of str_match:\n\npenguins_raw %&gt;% \n  select(Comments)\n\n# A tibble: 344 × 1\n   Comments                             \n   &lt;chr&gt;                                \n 1 Not enough blood for isotopes.       \n 2 &lt;NA&gt;                                 \n 3 &lt;NA&gt;                                 \n 4 Adult not sampled.                   \n 5 &lt;NA&gt;                                 \n 6 &lt;NA&gt;                                 \n 7 Nest never observed with full clutch.\n 8 Nest never observed with full clutch.\n 9 No blood sample obtained.            \n10 No blood sample obtained for sexing. \n# ℹ 334 more rows\n\n# Looking at the penguin_raw data there is a comments variable. If I were to want to find all observations that included a comment referencing a nest I could do so like this:\n\npenguins_raw %&gt;%  \n  mutate(match = str_match(Comments, pattern = \".*[Nn]est.*\")) %&gt;% \n  filter(!is.na(match)) %&gt;% \n  select(match, everything())\n\nWarning: Using one column matrices in `filter()` was deprecated in dplyr 1.1.0.\nℹ Please use one dimensional logical vectors instead.\n\n\n# A tibble: 36 × 18\n   match[,1]               studyName `Sample Number` Species Region Island Stage\n   &lt;chr&gt;                   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;\n 1 Nest never observed wi… PAL0708                 7 Adelie… Anvers Torge… Adul…\n 2 Nest never observed wi… PAL0708                 8 Adelie… Anvers Torge… Adul…\n 3 Nest never observed wi… PAL0708                29 Adelie… Anvers Biscoe Adul…\n 4 Nest never observed wi… PAL0708                30 Adelie… Anvers Biscoe Adul…\n 5 Nest never observed wi… PAL0708                39 Adelie… Anvers Dream  Adul…\n 6 Nest never observed wi… PAL0708                40 Adelie… Anvers Dream  Adul…\n 7 Nest never observed wi… PAL0809                69 Adelie… Anvers Torge… Adul…\n 8 Nest never observed wi… PAL0809                70 Adelie… Anvers Torge… Adul…\n 9 Nest never observed wi… PAL0910               121 Adelie… Anvers Torge… Adul…\n10 Nest never observed wi… PAL0910               122 Adelie… Anvers Torge… Adul…\n# ℹ 26 more rows\n# ℹ 11 more variables: `Individual ID` &lt;chr&gt;, `Clutch Completion` &lt;chr&gt;,\n#   `Date Egg` &lt;date&gt;, `Culmen Length (mm)` &lt;dbl&gt;, `Culmen Depth (mm)` &lt;dbl&gt;,\n#   `Flipper Length (mm)` &lt;dbl&gt;, `Body Mass (g)` &lt;dbl&gt;, Sex &lt;chr&gt;,\n#   `Delta 15 N (o/oo)` &lt;dbl&gt;, `Delta 13 C (o/oo)` &lt;dbl&gt;, Comments &lt;chr&gt;"
  },
  {
    "objectID": "function_of_the_week_Higbee.html",
    "href": "function_of_the_week_Higbee.html",
    "title": "forcats::fct_shift",
    "section": "",
    "text": "In this document, I will introduce the ’fct_shift` function and show what it’s for.\n\n#load tidyverse up\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npacman::p_load(\n  tidyverse,    # data management + ggplot2 graphics \n  readxl,       # import excel data\n  here,         # helps with file management\n  janitor,       # for data cleaning, making tables\n  skimr,\n  titanic       # needed to use the titanic dataset\n  )\n\n#install 'forcats'\n#install.packages(\"forcats\")\nlibrary(forcats) #load forcats package\nlibrary(datasets) #load built in datasets to r\n\n#example dataset\ndata(\"Orange\")\ndata(\"titanic_train\")\n\n\n\n\nDiscuss what the function does. Learn from the examples, but show how to use it using another dataset such as penguins. If you can provide two examples, even better!\n\nShift factor levels left or right, wrapping around at the end.\n\n\nThis function is from the ‘forcats’ package and is used to shift levels in a factor. The following is the syntax:\n\n\n\nSyntax\n\n\n\\(\\text{f = A factor}\\)\n\\(\\text{n = positive values shift to the left; negative values shift to the right}\\)\n\n\n\n\n\nShift Left\n\n\n\n\n\n\n\n\nShift Right\n\n\n\n\n\n\n\nx &lt;- factor(\n  c(\"Mon\", \"Tue\", \"Wed\"),\n  levels = c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"),\n  ordered = TRUE\n)\nx\n\n[1] Mon Tue Wed\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\nfct_shift(x) #default to shift left 1\n\n[1] Mon Tue Wed\nLevels: Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat &lt; Sun\n\nfct_shift(x, 2)\n\n[1] Mon Tue Wed\nLevels: Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat &lt; Sun &lt; Mon\n\nfct_shift(x, -1)\n\n[1] Mon Tue Wed\nLevels: Sat &lt; Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri\n\n\n\n\n\n\nglimpse(Orange)\n\nRows: 35\nColumns: 3\n$ Tree          &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,…\n$ age           &lt;dbl&gt; 118, 484, 664, 1004, 1231, 1372, 1582, 118, 484, 664, 10…\n$ circumference &lt;dbl&gt; 30, 58, 87, 115, 120, 142, 145, 33, 69, 111, 156, 172, 2…\n\nfactor(Orange$Tree)\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 3 &lt; 1 &lt; 5 &lt; 2 &lt; 4\n\nOrange$Tree &lt;- factor(Orange$Tree,\n    levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\nlevels(Orange$Tree)\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\ntabyl(Orange$Tree)\n\n Orange$Tree n percent\n           1 7     0.2\n           2 7     0.2\n           3 7     0.2\n           4 7     0.2\n           5 7     0.2\n\nfct_shift(Orange$Tree) # default to shift 1 left\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 2 &lt; 3 &lt; 4 &lt; 5 &lt; 1\n\nfct_shift(Orange$Tree, 1) # shift left\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 2 &lt; 3 &lt; 4 &lt; 5 &lt; 1\n\nfct_shift(Orange$Tree, -1) # shift right\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 5 &lt; 1 &lt; 2 &lt; 3 &lt; 4\n\nfct_shift(Orange$Tree, 4)\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 5 &lt; 1 &lt; 2 &lt; 3 &lt; 4\n\n\n\n\n\n\nglimpse(titanic_train)\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\n\nTitantic Voyage Map\n\n\n\nfactor(titanic_train$Embarked)\n\n  [1] S C S S S Q S S S C S S S S S S Q S S C S S Q S S S C S Q S C C Q S C S C\n [38] S S C S S C C Q S Q Q C S S S C S C S S C S S C   S S C C S S S S S S S C\n [75] S S S S S S S S Q S S S S S S S S S S S S S C C S S S S S S S S S S S Q S\n[112] C S S C S Q S C S S S C S S C Q S C S C S S S S C S S S C C S S Q S S S S\n[149] S S S S S S S C Q S S S S S S S S S S S S S S Q S S C S S C S S S C S S S\n[186] S Q S Q S S S S S C C Q S Q S S S S C S S S C Q C S S S S Q C S S C S S S\n[223] S S S S S S S S S S S S S S S S S S C Q S S C Q S S S S S S S S S C C S C\n[260] S Q S S S Q S S S S S S S S C Q S S S Q S Q S S S S C S S S Q S C C S S C\n[297] C S S C Q Q S Q S S C C C C C C S S S S S S S C S S Q S S C S S S C Q S S\n[334] S S S S C S S S S S S S S S S S S S S C S C S S S Q Q S C C S Q S C C Q C\n[371] C S S C S C S C C S C C S S S S S S Q C S S S C S S S S S S S S S S S S S\n[408] S S S S Q Q S S S S S S S C Q S S S S S S Q S S S S S S S S S S S S S S S\n[445] S S S S C S S S C C S C S S S Q S S S S S S S S Q C S S S C S S S S S S S\n[482] S S S C S S C S S S S S C S C C S S S S Q Q S S C S S S S Q S S C S S S Q\n[519] S S S S C C C Q S S S S S C C C S S S C S C S S S S C S S C S S C S Q C S\n[556] S C C S S Q S S S S S S S C S S S S Q S S S S C S S C S C C S S C S S S C\n[593] S Q S S S S C C S S S S C S S S C S S S Q Q S S S S S S C S C S S S Q S S\n[630] Q S S C S S S S S S S S C S S C C S C S S S S S Q Q S S Q S C S C S S S S\n[667] S S S S S S S S S S S S S C Q C S S S C S S S S S C S C S S S Q C S C S C\n[704] Q S S S S S C C S S S S S C S Q S S S S S S S S Q S S S C S S S S S C S S\n[741] S S C S S S S S S Q S S S S S S S S S S S S C S S S C Q Q S S S S C S S Q\n[778] S Q S C S S S S S S Q S C Q S S C S S S S C S S S S C S S S S S S S S S S\n[815] S S S C S S S S S S S Q S C Q   C S C S S C S S S C S S C C S S S C S C S\n[852] S C S S S S S C C S S S S S S C S S S S S S S C C S S S C S S S S S Q S S\n[889] S C Q\nLevels:  C Q S\n\ntitanic_train$Embarked &lt;- factor(titanic_train$Embarked,\n  levels = c(\"C\", \"Q\", \"S\")\n)\n\nlevels(titanic_train$Embarked)\n\n[1] \"C\" \"Q\" \"S\"\n\n\nLevels are in alphabetical order.\nWe want the ‘Embarked’ column to be in order of the actual voyage of the Titanic. Southampton &gt; Cherbourg &gt; Queenstown\n\nfct_shift(titanic_train$Embarked, -1)\n\n  [1] S    C    S    S    S    Q    S    S    S    C    S    S    S    S    S   \n [16] S    Q    S    S    C    S    S    Q    S    S    S    C    S    Q    S   \n [31] C    C    Q    S    C    S    C    S    S    C    S    S    C    C    Q   \n [46] S    Q    Q    C    S    S    S    C    S    C    S    S    C    S    S   \n [61] C    &lt;NA&gt; S    S    C    C    S    S    S    S    S    S    S    C    S   \n [76] S    S    S    S    S    S    S    Q    S    S    S    S    S    S    S   \n [91] S    S    S    S    S    S    C    C    S    S    S    S    S    S    S   \n[106] S    S    S    S    Q    S    C    S    S    C    S    Q    S    C    S   \n[121] S    S    C    S    S    C    Q    S    C    S    C    S    S    S    S   \n[136] C    S    S    S    C    C    S    S    Q    S    S    S    S    S    S   \n[151] S    S    S    S    S    C    Q    S    S    S    S    S    S    S    S   \n[166] S    S    S    S    S    S    Q    S    S    C    S    S    C    S    S   \n[181] S    C    S    S    S    S    Q    S    Q    S    S    S    S    S    C   \n[196] C    Q    S    Q    S    S    S    S    C    S    S    S    C    Q    C   \n[211] S    S    S    S    Q    C    S    S    C    S    S    S    S    S    S   \n[226] S    S    S    S    S    S    S    S    S    S    S    S    S    S    S   \n[241] C    Q    S    S    C    Q    S    S    S    S    S    S    S    S    S   \n[256] C    C    S    C    S    Q    S    S    S    Q    S    S    S    S    S   \n[271] S    S    S    C    Q    S    S    S    Q    S    Q    S    S    S    S   \n[286] C    S    S    S    Q    S    C    C    S    S    C    C    S    S    C   \n[301] Q    Q    S    Q    S    S    C    C    C    C    C    C    S    S    S   \n[316] S    S    S    S    C    S    S    Q    S    S    C    S    S    S    C   \n[331] Q    S    S    S    S    S    S    C    S    S    S    S    S    S    S   \n[346] S    S    S    S    S    S    S    C    S    C    S    S    S    Q    Q   \n[361] S    C    C    S    Q    S    C    C    Q    C    C    S    S    C    S   \n[376] C    S    C    C    S    C    C    S    S    S    S    S    S    Q    C   \n[391] S    S    S    C    S    S    S    S    S    S    S    S    S    S    S   \n[406] S    S    S    S    S    S    Q    Q    S    S    S    S    S    S    S   \n[421] C    Q    S    S    S    S    S    S    Q    S    S    S    S    S    S   \n[436] S    S    S    S    S    S    S    S    S    S    S    S    S    C    S   \n[451] S    S    C    C    S    C    S    S    S    Q    S    S    S    S    S   \n[466] S    S    S    Q    C    S    S    S    C    S    S    S    S    S    S   \n[481] S    S    S    S    C    S    S    C    S    S    S    S    S    C    S   \n[496] C    C    S    S    S    S    Q    Q    S    S    C    S    S    S    S   \n[511] Q    S    S    C    S    S    S    Q    S    S    S    S    C    C    C   \n[526] Q    S    S    S    S    S    C    C    C    S    S    S    C    S    C   \n[541] S    S    S    S    C    S    S    C    S    S    C    S    Q    C    S   \n[556] S    C    C    S    S    Q    S    S    S    S    S    S    S    C    S   \n[571] S    S    S    Q    S    S    S    S    C    S    S    C    S    C    C   \n[586] S    S    C    S    S    S    C    S    Q    S    S    S    S    C    C   \n[601] S    S    S    S    C    S    S    S    C    S    S    S    Q    Q    S   \n[616] S    S    S    S    S    C    S    C    S    S    S    Q    S    S    Q   \n[631] S    S    C    S    S    S    S    S    S    S    S    C    S    S    C   \n[646] C    S    C    S    S    S    S    S    Q    Q    S    S    Q    S    C   \n[661] S    C    S    S    S    S    S    S    S    S    S    S    S    S    S   \n[676] S    S    S    S    C    Q    C    S    S    S    C    S    S    S    S   \n[691] S    C    S    C    S    S    S    Q    C    S    C    S    C    Q    S   \n[706] S    S    S    S    C    C    S    S    S    S    S    C    S    Q    S   \n[721] S    S    S    S    S    S    S    Q    S    S    S    C    S    S    S   \n[736] S    S    C    S    S    S    S    C    S    S    S    S    S    S    Q   \n[751] S    S    S    S    S    S    S    S    S    S    S    S    C    S    S   \n[766] S    C    Q    Q    S    S    S    S    C    S    S    Q    S    Q    S   \n[781] C    S    S    S    S    S    S    Q    S    C    Q    S    S    C    S   \n[796] S    S    S    C    S    S    S    S    C    S    S    S    S    S    S   \n[811] S    S    S    S    S    S    S    C    S    S    S    S    S    S    S   \n[826] Q    S    C    Q    &lt;NA&gt; C    S    C    S    S    C    S    S    S    C   \n[841] S    S    C    C    S    S    S    C    S    C    S    S    C    S    S   \n[856] S    S    S    C    C    S    S    S    S    S    S    C    S    S    S   \n[871] S    S    S    S    C    C    S    S    S    C    S    S    S    S    S   \n[886] Q    S    S    S    C    Q   \nLevels: S C Q\n\ntitanic_train %&gt;% \n  mutate(Embarked = fct_shift(Embarked, -1)) %&gt;% \n  tabyl(Embarked)\n\n Embarked   n     percent valid_percent\n        S 644 0.722783389    0.72440945\n        C 168 0.188552189    0.18897638\n        Q  77 0.086419753    0.08661417\n     &lt;NA&gt;   2 0.002244669            NA\n\n\n\n\n\n\n\nDiscuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\n\nThis function is helpful! Instead of having to rewrite the entire order of the levels of a factor, you can easily use ‘fct_shift’ to reorder. However, it should be noted that this is useful when ordered factors are cyclical. So cannot work if you are pulling out a singular factor level to place somewhere else.\nCitation for titanic dataset: https://cran.r-project.org/web/packages/explore/vignettes/explore_titanic.html\nCitation for titantic voyage picture: https://en.m.wikipedia.org/wiki/File:Titanic_voyage_map.png"
  },
  {
    "objectID": "function_of_the_week_Higbee.html#what-is-it-for",
    "href": "function_of_the_week_Higbee.html#what-is-it-for",
    "title": "forcats::fct_shift",
    "section": "",
    "text": "Discuss what the function does. Learn from the examples, but show how to use it using another dataset such as penguins. If you can provide two examples, even better!\n\nShift factor levels left or right, wrapping around at the end.\n\n\nThis function is from the ‘forcats’ package and is used to shift levels in a factor. The following is the syntax:\n\n\n\nSyntax\n\n\n\\(\\text{f = A factor}\\)\n\\(\\text{n = positive values shift to the left; negative values shift to the right}\\)\n\n\n\n\n\nShift Left\n\n\n\n\n\n\n\n\nShift Right\n\n\n\n\n\n\n\nx &lt;- factor(\n  c(\"Mon\", \"Tue\", \"Wed\"),\n  levels = c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"),\n  ordered = TRUE\n)\nx\n\n[1] Mon Tue Wed\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\nfct_shift(x) #default to shift left 1\n\n[1] Mon Tue Wed\nLevels: Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat &lt; Sun\n\nfct_shift(x, 2)\n\n[1] Mon Tue Wed\nLevels: Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat &lt; Sun &lt; Mon\n\nfct_shift(x, -1)\n\n[1] Mon Tue Wed\nLevels: Sat &lt; Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri\n\n\n\n\n\n\nglimpse(Orange)\n\nRows: 35\nColumns: 3\n$ Tree          &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,…\n$ age           &lt;dbl&gt; 118, 484, 664, 1004, 1231, 1372, 1582, 118, 484, 664, 10…\n$ circumference &lt;dbl&gt; 30, 58, 87, 115, 120, 142, 145, 33, 69, 111, 156, 172, 2…\n\nfactor(Orange$Tree)\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 3 &lt; 1 &lt; 5 &lt; 2 &lt; 4\n\nOrange$Tree &lt;- factor(Orange$Tree,\n    levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\nlevels(Orange$Tree)\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\ntabyl(Orange$Tree)\n\n Orange$Tree n percent\n           1 7     0.2\n           2 7     0.2\n           3 7     0.2\n           4 7     0.2\n           5 7     0.2\n\nfct_shift(Orange$Tree) # default to shift 1 left\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 2 &lt; 3 &lt; 4 &lt; 5 &lt; 1\n\nfct_shift(Orange$Tree, 1) # shift left\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 2 &lt; 3 &lt; 4 &lt; 5 &lt; 1\n\nfct_shift(Orange$Tree, -1) # shift right\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 5 &lt; 1 &lt; 2 &lt; 3 &lt; 4\n\nfct_shift(Orange$Tree, 4)\n\n [1] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 3 3 4 4 4 4 4 4 4 5 5 5 5 5 5 5\nLevels: 5 &lt; 1 &lt; 2 &lt; 3 &lt; 4\n\n\n\n\n\n\nglimpse(titanic_train)\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\n\nTitantic Voyage Map\n\n\n\nfactor(titanic_train$Embarked)\n\n  [1] S C S S S Q S S S C S S S S S S Q S S C S S Q S S S C S Q S C C Q S C S C\n [38] S S C S S C C Q S Q Q C S S S C S C S S C S S C   S S C C S S S S S S S C\n [75] S S S S S S S S Q S S S S S S S S S S S S S C C S S S S S S S S S S S Q S\n[112] C S S C S Q S C S S S C S S C Q S C S C S S S S C S S S C C S S Q S S S S\n[149] S S S S S S S C Q S S S S S S S S S S S S S S Q S S C S S C S S S C S S S\n[186] S Q S Q S S S S S C C Q S Q S S S S C S S S C Q C S S S S Q C S S C S S S\n[223] S S S S S S S S S S S S S S S S S S C Q S S C Q S S S S S S S S S C C S C\n[260] S Q S S S Q S S S S S S S S C Q S S S Q S Q S S S S C S S S Q S C C S S C\n[297] C S S C Q Q S Q S S C C C C C C S S S S S S S C S S Q S S C S S S C Q S S\n[334] S S S S C S S S S S S S S S S S S S S C S C S S S Q Q S C C S Q S C C Q C\n[371] C S S C S C S C C S C C S S S S S S Q C S S S C S S S S S S S S S S S S S\n[408] S S S S Q Q S S S S S S S C Q S S S S S S Q S S S S S S S S S S S S S S S\n[445] S S S S C S S S C C S C S S S Q S S S S S S S S Q C S S S C S S S S S S S\n[482] S S S C S S C S S S S S C S C C S S S S Q Q S S C S S S S Q S S C S S S Q\n[519] S S S S C C C Q S S S S S C C C S S S C S C S S S S C S S C S S C S Q C S\n[556] S C C S S Q S S S S S S S C S S S S Q S S S S C S S C S C C S S C S S S C\n[593] S Q S S S S C C S S S S C S S S C S S S Q Q S S S S S S C S C S S S Q S S\n[630] Q S S C S S S S S S S S C S S C C S C S S S S S Q Q S S Q S C S C S S S S\n[667] S S S S S S S S S S S S S C Q C S S S C S S S S S C S C S S S Q C S C S C\n[704] Q S S S S S C C S S S S S C S Q S S S S S S S S Q S S S C S S S S S C S S\n[741] S S C S S S S S S Q S S S S S S S S S S S S C S S S C Q Q S S S S C S S Q\n[778] S Q S C S S S S S S Q S C Q S S C S S S S C S S S S C S S S S S S S S S S\n[815] S S S C S S S S S S S Q S C Q   C S C S S C S S S C S S C C S S S C S C S\n[852] S C S S S S S C C S S S S S S C S S S S S S S C C S S S C S S S S S Q S S\n[889] S C Q\nLevels:  C Q S\n\ntitanic_train$Embarked &lt;- factor(titanic_train$Embarked,\n  levels = c(\"C\", \"Q\", \"S\")\n)\n\nlevels(titanic_train$Embarked)\n\n[1] \"C\" \"Q\" \"S\"\n\n\nLevels are in alphabetical order.\nWe want the ‘Embarked’ column to be in order of the actual voyage of the Titanic. Southampton &gt; Cherbourg &gt; Queenstown\n\nfct_shift(titanic_train$Embarked, -1)\n\n  [1] S    C    S    S    S    Q    S    S    S    C    S    S    S    S    S   \n [16] S    Q    S    S    C    S    S    Q    S    S    S    C    S    Q    S   \n [31] C    C    Q    S    C    S    C    S    S    C    S    S    C    C    Q   \n [46] S    Q    Q    C    S    S    S    C    S    C    S    S    C    S    S   \n [61] C    &lt;NA&gt; S    S    C    C    S    S    S    S    S    S    S    C    S   \n [76] S    S    S    S    S    S    S    Q    S    S    S    S    S    S    S   \n [91] S    S    S    S    S    S    C    C    S    S    S    S    S    S    S   \n[106] S    S    S    S    Q    S    C    S    S    C    S    Q    S    C    S   \n[121] S    S    C    S    S    C    Q    S    C    S    C    S    S    S    S   \n[136] C    S    S    S    C    C    S    S    Q    S    S    S    S    S    S   \n[151] S    S    S    S    S    C    Q    S    S    S    S    S    S    S    S   \n[166] S    S    S    S    S    S    Q    S    S    C    S    S    C    S    S   \n[181] S    C    S    S    S    S    Q    S    Q    S    S    S    S    S    C   \n[196] C    Q    S    Q    S    S    S    S    C    S    S    S    C    Q    C   \n[211] S    S    S    S    Q    C    S    S    C    S    S    S    S    S    S   \n[226] S    S    S    S    S    S    S    S    S    S    S    S    S    S    S   \n[241] C    Q    S    S    C    Q    S    S    S    S    S    S    S    S    S   \n[256] C    C    S    C    S    Q    S    S    S    Q    S    S    S    S    S   \n[271] S    S    S    C    Q    S    S    S    Q    S    Q    S    S    S    S   \n[286] C    S    S    S    Q    S    C    C    S    S    C    C    S    S    C   \n[301] Q    Q    S    Q    S    S    C    C    C    C    C    C    S    S    S   \n[316] S    S    S    S    C    S    S    Q    S    S    C    S    S    S    C   \n[331] Q    S    S    S    S    S    S    C    S    S    S    S    S    S    S   \n[346] S    S    S    S    S    S    S    C    S    C    S    S    S    Q    Q   \n[361] S    C    C    S    Q    S    C    C    Q    C    C    S    S    C    S   \n[376] C    S    C    C    S    C    C    S    S    S    S    S    S    Q    C   \n[391] S    S    S    C    S    S    S    S    S    S    S    S    S    S    S   \n[406] S    S    S    S    S    S    Q    Q    S    S    S    S    S    S    S   \n[421] C    Q    S    S    S    S    S    S    Q    S    S    S    S    S    S   \n[436] S    S    S    S    S    S    S    S    S    S    S    S    S    C    S   \n[451] S    S    C    C    S    C    S    S    S    Q    S    S    S    S    S   \n[466] S    S    S    Q    C    S    S    S    C    S    S    S    S    S    S   \n[481] S    S    S    S    C    S    S    C    S    S    S    S    S    C    S   \n[496] C    C    S    S    S    S    Q    Q    S    S    C    S    S    S    S   \n[511] Q    S    S    C    S    S    S    Q    S    S    S    S    C    C    C   \n[526] Q    S    S    S    S    S    C    C    C    S    S    S    C    S    C   \n[541] S    S    S    S    C    S    S    C    S    S    C    S    Q    C    S   \n[556] S    C    C    S    S    Q    S    S    S    S    S    S    S    C    S   \n[571] S    S    S    Q    S    S    S    S    C    S    S    C    S    C    C   \n[586] S    S    C    S    S    S    C    S    Q    S    S    S    S    C    C   \n[601] S    S    S    S    C    S    S    S    C    S    S    S    Q    Q    S   \n[616] S    S    S    S    S    C    S    C    S    S    S    Q    S    S    Q   \n[631] S    S    C    S    S    S    S    S    S    S    S    C    S    S    C   \n[646] C    S    C    S    S    S    S    S    Q    Q    S    S    Q    S    C   \n[661] S    C    S    S    S    S    S    S    S    S    S    S    S    S    S   \n[676] S    S    S    S    C    Q    C    S    S    S    C    S    S    S    S   \n[691] S    C    S    C    S    S    S    Q    C    S    C    S    C    Q    S   \n[706] S    S    S    S    C    C    S    S    S    S    S    C    S    Q    S   \n[721] S    S    S    S    S    S    S    Q    S    S    S    C    S    S    S   \n[736] S    S    C    S    S    S    S    C    S    S    S    S    S    S    Q   \n[751] S    S    S    S    S    S    S    S    S    S    S    S    C    S    S   \n[766] S    C    Q    Q    S    S    S    S    C    S    S    Q    S    Q    S   \n[781] C    S    S    S    S    S    S    Q    S    C    Q    S    S    C    S   \n[796] S    S    S    C    S    S    S    S    C    S    S    S    S    S    S   \n[811] S    S    S    S    S    S    S    C    S    S    S    S    S    S    S   \n[826] Q    S    C    Q    &lt;NA&gt; C    S    C    S    S    C    S    S    S    C   \n[841] S    S    C    C    S    S    S    C    S    C    S    S    C    S    S   \n[856] S    S    S    C    C    S    S    S    S    S    S    C    S    S    S   \n[871] S    S    S    S    C    C    S    S    S    C    S    S    S    S    S   \n[886] Q    S    S    S    C    Q   \nLevels: S C Q\n\ntitanic_train %&gt;% \n  mutate(Embarked = fct_shift(Embarked, -1)) %&gt;% \n  tabyl(Embarked)\n\n Embarked   n     percent valid_percent\n        S 644 0.722783389    0.72440945\n        C 168 0.188552189    0.18897638\n        Q  77 0.086419753    0.08661417\n     &lt;NA&gt;   2 0.002244669            NA"
  },
  {
    "objectID": "function_of_the_week_Higbee.html#is-it-helpful",
    "href": "function_of_the_week_Higbee.html#is-it-helpful",
    "title": "forcats::fct_shift",
    "section": "",
    "text": "Discuss whether you think this function is useful for you and your work. Is it the best thing since sliced bread, or is it not really relevant to your work?\n\nThis function is helpful! Instead of having to rewrite the entire order of the levels of a factor, you can easily use ‘fct_shift’ to reorder. However, it should be noted that this is useful when ordered factors are cyclical. So cannot work if you are pulling out a singular factor level to place somewhere else.\nCitation for titanic dataset: https://cran.r-project.org/web/packages/explore/vignettes/explore_titanic.html\nCitation for titantic voyage picture: https://en.m.wikipedia.org/wiki/File:Titanic_voyage_map.png"
  },
  {
    "objectID": "function_of_the_week_KELLY.html",
    "href": "function_of_the_week_KELLY.html",
    "title": "dplyr::near()",
    "section": "",
    "text": "In this document, I will introduce the near() function and show what it’s for.\n\n\nLet’s say we wanted to test for equivalency between 2 numeric vectors. Many might approach this situation using == to compare the two, which we will see does not always work the way we might intend.\nWe’ll start with a simple example (adapted from Wickham et al. 2023). First I will create a numeric vector with just 2 values.\n\n#Create a vector with 2 values:\nx &lt;- c(1/49*49, sqrt(2)^2)\n\n# Check the values of vector x:\nx\n\n[1] 1 2\n\n\nSo if the values of the vector x are (1,2), what will happen if I test this vector for equality using == with another numeric vector y which also has the values of (1,2)?\n\n#Create a y vector with the same 2 values (1,2):\ny &lt;- c(1,2)\n\n#Test the x and y vectors for equality with each other using ==:\nx == y\n\n[1] FALSE FALSE\n\n\nWhat happened?? Let’s take a closer look at the values of x, which we can see in more detail by using the print() function, and specifying the number of decimal points we want to see in the output.\n\n#Check the exact values of vector x\nprint(x, digits = 16)\n\n[1] 0.9999999999999999 2.0000000000000004\n\n\nThis output shows us that R actually defaults to rounding up when we ask it to show us the values of the vector x with the usual command x, but it still knows the values aren’t exactly (1,2), which is why it told us FALSE FALSE when we tested vector x for equality with vector y.\nIn these situations, the near() function could be more useful, as it ignores very small differences.\n\n#Test the x and y vectors for equality with each other using near():\nnear(x, y)\n\n[1] TRUE TRUE\n\n\nLet’s try using the near() function now with a data set, we will come back to the ol’ penguins we all know and love. What if, for example, we wanted to check if the bill length of male penguins is similar to the bill length of female penguins in the sample.\nIn using near(), first you’ve got to be sure the vectors you are comparing have the same number of values. So we’ll adjust our data set slightly, dropping those with bill lengths greater than 55 mm to ensure we are comparing the same number of males to females.\n\n#Reduce the data set to just bill length and sex\npenguins_reduced &lt;- penguins %&gt;% \n  select(bill_length_mm,\n         sex)\n\n#Create a vector with bill length values for male penguins\npenguins_male &lt;- penguins_reduced %&gt;% \n  filter(sex == \"male\" &\n           bill_length_mm &lt; 55)\n\n#Create a vector with bill length values for female penguins\npenguins_female &lt;- penguins_reduced %&gt;% \n  filter(sex == \"female\" &\n           bill_length_mm &lt; 55)\n\nNow we have our 2 vectors to compare, with n= 164 each. When testing for equality, the near function has a specification we can use for the level of difference we want it to tolerate. Let’s set it to a tolerance level of 1 mm.\n\n#Test for equality using near(), with our tolerance specification:\nnear(penguins_male$bill_length_mm, penguins_female$bill_length_mm, tol = 1)\n\n  [1]  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE\n [13]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [37] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n [49]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [85]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n [97]  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE\n[109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE\n[157] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n\n\nHmm, ok, but maybe it would be useful if I could see some kind of summary of this output…\n\ncount_TRUE &lt;- near(penguins_male$bill_length_mm, penguins_female$bill_length_mm, tol = 1)\ntabyl(count_TRUE)\n\n count_TRUE   n   percent\n      FALSE 141 0.8597561\n       TRUE  23 0.1402439\n\n\n\n\n\nI think the near() function could be helpful in certain situations. One type of situation would be when exploring a data set, to obtain rough estimates of certain questions, without having to initially get too precise about the values.\nAnother type of situation could be in exploring repeated measures data. Imagine for example in the penguins data set, if it included measurements from the same penguins over time, starting when they were born. The near() function could be used to explore whether the penguins grow at roughly similar rates.\nThoughts or questions?\nReferences:\nWickham, H., Çetinkaya-Rundel, M., and Grolemund, G. (2023). R for Data Science (2e). https://r4ds.hadley.nz"
  },
  {
    "objectID": "function_of_the_week_KELLY.html#what-is-it-for",
    "href": "function_of_the_week_KELLY.html#what-is-it-for",
    "title": "dplyr::near()",
    "section": "",
    "text": "Let’s say we wanted to test for equivalency between 2 numeric vectors. Many might approach this situation using == to compare the two, which we will see does not always work the way we might intend.\nWe’ll start with a simple example (adapted from Wickham et al. 2023). First I will create a numeric vector with just 2 values.\n\n#Create a vector with 2 values:\nx &lt;- c(1/49*49, sqrt(2)^2)\n\n# Check the values of vector x:\nx\n\n[1] 1 2\n\n\nSo if the values of the vector x are (1,2), what will happen if I test this vector for equality using == with another numeric vector y which also has the values of (1,2)?\n\n#Create a y vector with the same 2 values (1,2):\ny &lt;- c(1,2)\n\n#Test the x and y vectors for equality with each other using ==:\nx == y\n\n[1] FALSE FALSE\n\n\nWhat happened?? Let’s take a closer look at the values of x, which we can see in more detail by using the print() function, and specifying the number of decimal points we want to see in the output.\n\n#Check the exact values of vector x\nprint(x, digits = 16)\n\n[1] 0.9999999999999999 2.0000000000000004\n\n\nThis output shows us that R actually defaults to rounding up when we ask it to show us the values of the vector x with the usual command x, but it still knows the values aren’t exactly (1,2), which is why it told us FALSE FALSE when we tested vector x for equality with vector y.\nIn these situations, the near() function could be more useful, as it ignores very small differences.\n\n#Test the x and y vectors for equality with each other using near():\nnear(x, y)\n\n[1] TRUE TRUE\n\n\nLet’s try using the near() function now with a data set, we will come back to the ol’ penguins we all know and love. What if, for example, we wanted to check if the bill length of male penguins is similar to the bill length of female penguins in the sample.\nIn using near(), first you’ve got to be sure the vectors you are comparing have the same number of values. So we’ll adjust our data set slightly, dropping those with bill lengths greater than 55 mm to ensure we are comparing the same number of males to females.\n\n#Reduce the data set to just bill length and sex\npenguins_reduced &lt;- penguins %&gt;% \n  select(bill_length_mm,\n         sex)\n\n#Create a vector with bill length values for male penguins\npenguins_male &lt;- penguins_reduced %&gt;% \n  filter(sex == \"male\" &\n           bill_length_mm &lt; 55)\n\n#Create a vector with bill length values for female penguins\npenguins_female &lt;- penguins_reduced %&gt;% \n  filter(sex == \"female\" &\n           bill_length_mm &lt; 55)\n\nNow we have our 2 vectors to compare, with n= 164 each. When testing for equality, the near function has a specification we can use for the level of difference we want it to tolerate. Let’s set it to a tolerance level of 1 mm.\n\n#Test for equality using near(), with our tolerance specification:\nnear(penguins_male$bill_length_mm, penguins_female$bill_length_mm, tol = 1)\n\n  [1]  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE\n [13]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [37] FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n [49]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [85]  TRUE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n [97]  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE\n[109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE\n[157] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n\n\nHmm, ok, but maybe it would be useful if I could see some kind of summary of this output…\n\ncount_TRUE &lt;- near(penguins_male$bill_length_mm, penguins_female$bill_length_mm, tol = 1)\ntabyl(count_TRUE)\n\n count_TRUE   n   percent\n      FALSE 141 0.8597561\n       TRUE  23 0.1402439"
  },
  {
    "objectID": "function_of_the_week_KELLY.html#is-it-helpful",
    "href": "function_of_the_week_KELLY.html#is-it-helpful",
    "title": "dplyr::near()",
    "section": "",
    "text": "I think the near() function could be helpful in certain situations. One type of situation would be when exploring a data set, to obtain rough estimates of certain questions, without having to initially get too precise about the values.\nAnother type of situation could be in exploring repeated measures data. Imagine for example in the penguins data set, if it included measurements from the same penguins over time, starting when they were born. The near() function could be used to explore whether the penguins grow at roughly similar rates.\nThoughts or questions?\nReferences:\nWickham, H., Çetinkaya-Rundel, M., and Grolemund, G. (2023). R for Data Science (2e). https://r4ds.hadley.nz"
  },
  {
    "objectID": "function_week_RUSSELL_reorder.html",
    "href": "function_week_RUSSELL_reorder.html",
    "title": "forcats::fct_inorder(), fct_infreq(), fct_inseq()",
    "section": "",
    "text": "In this document, I will introduce a set of functions that allows us to reorder the levels in factor variables.\n\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(ggplot2)\n\ndata(\"msleep\")\n\n\n\nWe’ve seen how to manually reorder factor levels, which is straightforward and allows for a lot of control… but is also a lot of typing. Using a data set on the sleeping patterns of mammals, we can see how this works.\nFirst, let’s create some factor variables in our data:\n\nglimpse(msleep)\n\nRows: 83\nColumns: 11\n$ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater shor…\n$ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"Bra…\n$ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"carn…\n$ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"Art…\n$ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"dome…\n$ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0, 5…\n$ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.8, …\n$ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833333, N…\n$ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0, 1…\n$ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000, 0…\n$ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0.04…\n\nmsleep2 &lt;- msleep %&gt;% \n  mutate(vore_factor = factor(vore),\n         order_factor = factor(order),\n         sleep_total_factor = case_when(\n           # Get ready for some super inappropriate rounding:\n           sleep_total &lt; 5 ~ 5,\n           sleep_total &gt;= 5 & sleep_total &lt; 10 ~ 10,\n           sleep_total &gt;= 10 & sleep_total &lt; 15 ~ 15,\n           sleep_total &gt;= 15 & sleep_total &lt; 20 ~ 20),\n         sleep_total_factor = factor(sleep_total_factor))\n\nglimpse(msleep2)\n\nRows: 83\nColumns: 14\n$ name               &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greate…\n$ genus              &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\"…\n$ vore               &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\",…\n$ order              &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\"…\n$ conservation       &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA,…\n$ sleep_total        &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, …\n$ sleep_rem          &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6,…\n$ sleep_cycle        &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833…\n$ awake              &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 2…\n$ brainwt            &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07…\n$ bodywt             &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490…\n$ vore_factor        &lt;fct&gt; carni, omni, herbi, omni, herbi, herbi, carni, NA, …\n$ order_factor       &lt;fct&gt; Carnivora, Primates, Rodentia, Soricomorpha, Artiod…\n$ sleep_total_factor &lt;fct&gt; 15, 20, 15, 15, 5, 15, 10, 10, 15, 5, 10, 10, 15, 1…\n\n\nNow let’s look at a nice table of our new factor variables:\n\nmsleep2 %&gt;% \n  select(vore_factor, order_factor, sleep_total_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    vore_factor\n\n        carni\n19 (25%)\n        herbi\n32 (42%)\n        insecti\n5 (6.6%)\n        omni\n20 (26%)\n        Unknown\n7\n    order_factor\n\n        Afrosoricida\n1 (1.2%)\n        Artiodactyla\n6 (7.2%)\n        Carnivora\n12 (14%)\n        Cetacea\n3 (3.6%)\n        Chiroptera\n2 (2.4%)\n        Cingulata\n2 (2.4%)\n        Didelphimorphia\n2 (2.4%)\n        Diprotodontia\n2 (2.4%)\n        Erinaceomorpha\n2 (2.4%)\n        Hyracoidea\n3 (3.6%)\n        Lagomorpha\n1 (1.2%)\n        Monotremata\n1 (1.2%)\n        Perissodactyla\n3 (3.6%)\n        Pilosa\n1 (1.2%)\n        Primates\n12 (14%)\n        Proboscidea\n2 (2.4%)\n        Rodentia\n22 (27%)\n        Scandentia\n1 (1.2%)\n        Soricomorpha\n5 (6.0%)\n    sleep_total_factor\n\n        5\n11 (13%)\n        10\n27 (33%)\n        15\n33 (40%)\n        20\n12 (14%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nOk, so our new factor levels have defaulted to alpha-numeric order, but maybe that’s not how we want them. Re-ordering them manually might look something like this:\n\nmsleep2 &lt;- msleep2 %&gt;% \n  mutate(vore_factor = factor(vore_factor,\n                                  ordered = T,\n                                  levels = c(\"omni\", \"insecti\", \"herbi\", \"carni\")))\n\nmsleep2 %&gt;% \n  select(vore_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    vore_factor\n\n        omni\n20 (26%)\n        insecti\n5 (6.6%)\n        herbi\n32 (42%)\n        carni\n19 (25%)\n        Unknown\n7\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nThis works, but could be a very unweildy process if we had a variable with a lot of factor levels, like our order variable. In addition, what if we wanted to order them in a different way, such as by frequency or by order in which they appear in our data? This would be hard to figure out manually!\nForcats has three ordering functions that can help us out.\nOrder of first appearance\nfct_inorder() will organize levels by the order in which they first appear. Let’s try that out on our vore factor levels. First, a quick look at the first rows of our msleep2 data set for reference:\n\nhead(msleep2)\n\n# A tibble: 6 × 14\n  name    genus vore  order conservation sleep_total sleep_rem sleep_cycle awake\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Cheetah Acin… carni Carn… lc                  12.1      NA        NA      11.9\n2 Owl mo… Aotus omni  Prim… &lt;NA&gt;                17         1.8      NA       7  \n3 Mounta… Aplo… herbi Rode… nt                  14.4       2.4      NA       9.6\n4 Greate… Blar… omni  Sori… lc                  14.9       2.3       0.133   9.1\n5 Cow     Bos   herbi Arti… domesticated         4         0.7       0.667  20  \n6 Three-… Brad… herbi Pilo… &lt;NA&gt;                14.4       2.2       0.767   9.6\n# ℹ 5 more variables: brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;, vore_factor &lt;ord&gt;,\n#   order_factor &lt;fct&gt;, sleep_total_factor &lt;fct&gt;\n\n\nNow let’s ask forcats to order our vore levels by the order of first appearance:\n\nfct_inorder(msleep2$vore_factor)\n\n [1] carni   omni    herbi   omni    herbi   herbi   carni   &lt;NA&gt;    carni  \n[10] herbi   herbi   herbi   omni    herbi   omni    omni    omni    carni  \n[19] herbi   omni    herbi   insecti herbi   herbi   omni    omni    herbi  \n[28] carni   omni    herbi   carni   carni   herbi   omni    herbi   herbi  \n[37] carni   omni    herbi   herbi   herbi   herbi   insecti herbi   carni  \n[46] herbi   carni   herbi   herbi   omni    carni   carni   carni   omni   \n[55] &lt;NA&gt;    omni    &lt;NA&gt;    &lt;NA&gt;    carni   carni   herbi   insecti &lt;NA&gt;   \n[64] herbi   omni    omni    insecti herbi   &lt;NA&gt;    herbi   herbi   herbi  \n[73] &lt;NA&gt;    omni    insecti herbi   herbi   omni    omni    carni   carni  \n[82] carni   carni  \nLevels: carni &lt; omni &lt; herbi &lt; insecti\n\nmsleep2 %&gt;% \n  mutate(vore_factor = vore_factor %&gt;% \n           fct_inorder()) %&gt;% \n  select(vore_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    vore_factor\n\n        carni\n19 (25%)\n        omni\n20 (26%)\n        herbi\n32 (42%)\n        insecti\n5 (6.6%)\n        Unknown\n7\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nNumber of observations\nfct_infreq will order levels by the number of observations within each level. Let’s try it with a graph this time. Before ordering, our graph might look like this:\n\nmsleep2 %&gt;% \n  ggplot(\n    aes(y = order_factor)) +\n  geom_bar()\n\n\n\n\nAlphabetical order is helpful in libraries, but not necessarily in graphs! Reordering using fct_infreq(), we get a more visually helpful graph:\n\nmsleep2 %&gt;% \n  mutate(order_factor = order_factor %&gt;% \n           fct_infreq()) %&gt;% \n  ggplot(aes(\n         y = order_factor)) +\n  geom_bar()\n\n\n\n\nWe can also reverse the order and go from highest frequency to lowest by using fct_rev() in combination with fct_infreq:\n\nmsleep2 %&gt;% \n  mutate(order_factor = order_factor %&gt;% \n           fct_infreq() %&gt;% \n           fct_rev()) %&gt;% \n  ggplot(aes(\n         y = order_factor)) +\n  geom_bar()\n\n\n\n\nNumeric sequencing\nfct_inseq will correctly sequence numeric factor levels:\n\nmsleep2 %&gt;% \n  select(sleep_total_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    sleep_total_factor\n\n        5\n11 (13%)\n        10\n27 (33%)\n        15\n33 (40%)\n        20\n12 (14%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\nfct_inseq(msleep2$sleep_total_factor)\n\n [1] 15 20 15 15 5  15 10 10 15 5  10 10 15 15 15 10 10 20 10 20 5  20 5  5  15\n[26] 15 15 15 10 5  5  10 10 10 10 5  20 15 15 15 15 15 20 15 15 10 15 10 5  10\n[51] 20 15 15 10 15 15 15 15 5  10 15 20 10 15 10 10 10 15 15 20 15 20 15 10 10\n[76] 20 5  20 10 10 10 15 10\nLevels: 5 10 15 20\n\nmsleep2 %&gt;% \n  mutate(sleep_total_factor = sleep_total_factor %&gt;% \n           fct_inseq() %&gt;% \n           fct_rev()) %&gt;% \n  select(sleep_total_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    sleep_total_factor\n\n        20\n12 (14%)\n        15\n33 (40%)\n        10\n27 (33%)\n        5\n11 (13%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n\nI think this family of functions could be very helpful, particularly the ordering by frequency of occurrence. I’m a little less sold on fct_inseq, mainly because R already seems to sequence numeric factor levels correctly (unless you want them reversed). I bet Meike and Emile have better knowledge of where this could come in handy, though…\n\n\n\nhttps://forcats.tidyverse.org/reference/fct_inorder.html\nhttps://livebook.manning.com/concept/r/fct_infreq"
  },
  {
    "objectID": "function_week_RUSSELL_reorder.html#what-is-it-for",
    "href": "function_week_RUSSELL_reorder.html#what-is-it-for",
    "title": "forcats::fct_inorder(), fct_infreq(), fct_inseq()",
    "section": "",
    "text": "We’ve seen how to manually reorder factor levels, which is straightforward and allows for a lot of control… but is also a lot of typing. Using a data set on the sleeping patterns of mammals, we can see how this works.\nFirst, let’s create some factor variables in our data:\n\nglimpse(msleep)\n\nRows: 83\nColumns: 11\n$ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater shor…\n$ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"Bra…\n$ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"carn…\n$ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"Art…\n$ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"dome…\n$ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0, 5…\n$ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.8, …\n$ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833333, N…\n$ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0, 1…\n$ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000, 0…\n$ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0.04…\n\nmsleep2 &lt;- msleep %&gt;% \n  mutate(vore_factor = factor(vore),\n         order_factor = factor(order),\n         sleep_total_factor = case_when(\n           # Get ready for some super inappropriate rounding:\n           sleep_total &lt; 5 ~ 5,\n           sleep_total &gt;= 5 & sleep_total &lt; 10 ~ 10,\n           sleep_total &gt;= 10 & sleep_total &lt; 15 ~ 15,\n           sleep_total &gt;= 15 & sleep_total &lt; 20 ~ 20),\n         sleep_total_factor = factor(sleep_total_factor))\n\nglimpse(msleep2)\n\nRows: 83\nColumns: 14\n$ name               &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greate…\n$ genus              &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\"…\n$ vore               &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\",…\n$ order              &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\"…\n$ conservation       &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA,…\n$ sleep_total        &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, …\n$ sleep_rem          &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6,…\n$ sleep_cycle        &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833…\n$ awake              &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 2…\n$ brainwt            &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07…\n$ bodywt             &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490…\n$ vore_factor        &lt;fct&gt; carni, omni, herbi, omni, herbi, herbi, carni, NA, …\n$ order_factor       &lt;fct&gt; Carnivora, Primates, Rodentia, Soricomorpha, Artiod…\n$ sleep_total_factor &lt;fct&gt; 15, 20, 15, 15, 5, 15, 10, 10, 15, 5, 10, 10, 15, 1…\n\n\nNow let’s look at a nice table of our new factor variables:\n\nmsleep2 %&gt;% \n  select(vore_factor, order_factor, sleep_total_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    vore_factor\n\n        carni\n19 (25%)\n        herbi\n32 (42%)\n        insecti\n5 (6.6%)\n        omni\n20 (26%)\n        Unknown\n7\n    order_factor\n\n        Afrosoricida\n1 (1.2%)\n        Artiodactyla\n6 (7.2%)\n        Carnivora\n12 (14%)\n        Cetacea\n3 (3.6%)\n        Chiroptera\n2 (2.4%)\n        Cingulata\n2 (2.4%)\n        Didelphimorphia\n2 (2.4%)\n        Diprotodontia\n2 (2.4%)\n        Erinaceomorpha\n2 (2.4%)\n        Hyracoidea\n3 (3.6%)\n        Lagomorpha\n1 (1.2%)\n        Monotremata\n1 (1.2%)\n        Perissodactyla\n3 (3.6%)\n        Pilosa\n1 (1.2%)\n        Primates\n12 (14%)\n        Proboscidea\n2 (2.4%)\n        Rodentia\n22 (27%)\n        Scandentia\n1 (1.2%)\n        Soricomorpha\n5 (6.0%)\n    sleep_total_factor\n\n        5\n11 (13%)\n        10\n27 (33%)\n        15\n33 (40%)\n        20\n12 (14%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nOk, so our new factor levels have defaulted to alpha-numeric order, but maybe that’s not how we want them. Re-ordering them manually might look something like this:\n\nmsleep2 &lt;- msleep2 %&gt;% \n  mutate(vore_factor = factor(vore_factor,\n                                  ordered = T,\n                                  levels = c(\"omni\", \"insecti\", \"herbi\", \"carni\")))\n\nmsleep2 %&gt;% \n  select(vore_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    vore_factor\n\n        omni\n20 (26%)\n        insecti\n5 (6.6%)\n        herbi\n32 (42%)\n        carni\n19 (25%)\n        Unknown\n7\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nThis works, but could be a very unweildy process if we had a variable with a lot of factor levels, like our order variable. In addition, what if we wanted to order them in a different way, such as by frequency or by order in which they appear in our data? This would be hard to figure out manually!\nForcats has three ordering functions that can help us out.\nOrder of first appearance\nfct_inorder() will organize levels by the order in which they first appear. Let’s try that out on our vore factor levels. First, a quick look at the first rows of our msleep2 data set for reference:\n\nhead(msleep2)\n\n# A tibble: 6 × 14\n  name    genus vore  order conservation sleep_total sleep_rem sleep_cycle awake\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Cheetah Acin… carni Carn… lc                  12.1      NA        NA      11.9\n2 Owl mo… Aotus omni  Prim… &lt;NA&gt;                17         1.8      NA       7  \n3 Mounta… Aplo… herbi Rode… nt                  14.4       2.4      NA       9.6\n4 Greate… Blar… omni  Sori… lc                  14.9       2.3       0.133   9.1\n5 Cow     Bos   herbi Arti… domesticated         4         0.7       0.667  20  \n6 Three-… Brad… herbi Pilo… &lt;NA&gt;                14.4       2.2       0.767   9.6\n# ℹ 5 more variables: brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;, vore_factor &lt;ord&gt;,\n#   order_factor &lt;fct&gt;, sleep_total_factor &lt;fct&gt;\n\n\nNow let’s ask forcats to order our vore levels by the order of first appearance:\n\nfct_inorder(msleep2$vore_factor)\n\n [1] carni   omni    herbi   omni    herbi   herbi   carni   &lt;NA&gt;    carni  \n[10] herbi   herbi   herbi   omni    herbi   omni    omni    omni    carni  \n[19] herbi   omni    herbi   insecti herbi   herbi   omni    omni    herbi  \n[28] carni   omni    herbi   carni   carni   herbi   omni    herbi   herbi  \n[37] carni   omni    herbi   herbi   herbi   herbi   insecti herbi   carni  \n[46] herbi   carni   herbi   herbi   omni    carni   carni   carni   omni   \n[55] &lt;NA&gt;    omni    &lt;NA&gt;    &lt;NA&gt;    carni   carni   herbi   insecti &lt;NA&gt;   \n[64] herbi   omni    omni    insecti herbi   &lt;NA&gt;    herbi   herbi   herbi  \n[73] &lt;NA&gt;    omni    insecti herbi   herbi   omni    omni    carni   carni  \n[82] carni   carni  \nLevels: carni &lt; omni &lt; herbi &lt; insecti\n\nmsleep2 %&gt;% \n  mutate(vore_factor = vore_factor %&gt;% \n           fct_inorder()) %&gt;% \n  select(vore_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    vore_factor\n\n        carni\n19 (25%)\n        omni\n20 (26%)\n        herbi\n32 (42%)\n        insecti\n5 (6.6%)\n        Unknown\n7\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nNumber of observations\nfct_infreq will order levels by the number of observations within each level. Let’s try it with a graph this time. Before ordering, our graph might look like this:\n\nmsleep2 %&gt;% \n  ggplot(\n    aes(y = order_factor)) +\n  geom_bar()\n\n\n\n\nAlphabetical order is helpful in libraries, but not necessarily in graphs! Reordering using fct_infreq(), we get a more visually helpful graph:\n\nmsleep2 %&gt;% \n  mutate(order_factor = order_factor %&gt;% \n           fct_infreq()) %&gt;% \n  ggplot(aes(\n         y = order_factor)) +\n  geom_bar()\n\n\n\n\nWe can also reverse the order and go from highest frequency to lowest by using fct_rev() in combination with fct_infreq:\n\nmsleep2 %&gt;% \n  mutate(order_factor = order_factor %&gt;% \n           fct_infreq() %&gt;% \n           fct_rev()) %&gt;% \n  ggplot(aes(\n         y = order_factor)) +\n  geom_bar()\n\n\n\n\nNumeric sequencing\nfct_inseq will correctly sequence numeric factor levels:\n\nmsleep2 %&gt;% \n  select(sleep_total_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    sleep_total_factor\n\n        5\n11 (13%)\n        10\n27 (33%)\n        15\n33 (40%)\n        20\n12 (14%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\nfct_inseq(msleep2$sleep_total_factor)\n\n [1] 15 20 15 15 5  15 10 10 15 5  10 10 15 15 15 10 10 20 10 20 5  20 5  5  15\n[26] 15 15 15 10 5  5  10 10 10 10 5  20 15 15 15 15 15 20 15 15 10 15 10 5  10\n[51] 20 15 15 10 15 15 15 15 5  10 15 20 10 15 10 10 10 15 15 20 15 20 15 10 10\n[76] 20 5  20 10 10 10 15 10\nLevels: 5 10 15 20\n\nmsleep2 %&gt;% \n  mutate(sleep_total_factor = sleep_total_factor %&gt;% \n           fct_inseq() %&gt;% \n           fct_rev()) %&gt;% \n  select(sleep_total_factor) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 831\n    \n  \n  \n    sleep_total_factor\n\n        20\n12 (14%)\n        15\n33 (40%)\n        10\n27 (33%)\n        5\n11 (13%)\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "function_week_RUSSELL_reorder.html#is-it-helpful",
    "href": "function_week_RUSSELL_reorder.html#is-it-helpful",
    "title": "forcats::fct_inorder(), fct_infreq(), fct_inseq()",
    "section": "",
    "text": "I think this family of functions could be very helpful, particularly the ordering by frequency of occurrence. I’m a little less sold on fct_inseq, mainly because R already seems to sequence numeric factor levels correctly (unless you want them reversed). I bet Meike and Emile have better knowledge of where this could come in handy, though…"
  },
  {
    "objectID": "function_week_RUSSELL_reorder.html#sources",
    "href": "function_week_RUSSELL_reorder.html#sources",
    "title": "forcats::fct_inorder(), fct_infreq(), fct_inseq()",
    "section": "",
    "text": "https://forcats.tidyverse.org/reference/fct_inorder.html\nhttps://livebook.manning.com/concept/r/fct_infreq"
  },
  {
    "objectID": "Function_of_the_Week_Weingarten.html",
    "href": "Function_of_the_Week_Weingarten.html",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "In this document, I will introduce the drop_na() function and show what it’s for.\n\n#load tidyverse up\nlibrary(tidyverse)\n#example dataset\nlibrary(palmerpenguins)\ndata(penguins)\n\n\n\nThe drop_na function will drop out rows from your dataset where columns contain missing values. It can take two arguments:\n\ndata : the name of your dataframe\n... : Columns to inspect for missing values. If not specified, all columns are inspected.\n\nExample code setup: data %&gt;% drop_na() or data %&gt;% drop_na(column_name)\n\n\n\n\n#How many NA's in our dataset?\n(sum(is.na(penguins)))\n\n[1] 19\n\n#What columns contain NA's?\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\n\n\n\n#Drop NA's from just one column\npenguins_dropNA_mass &lt;- penguins %&gt;% drop_na(body_mass_g)\nsummary(penguins_dropNA_mass)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :151   Biscoe   :167   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :123   Torgersen: 51   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  :  9   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n\n\n\n\n\n\n#Drop NA's from all columns\npenguins_dropNA_all &lt;- penguins %&gt;% drop_na()\nsummary(penguins_dropNA_all)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :146   Biscoe   :163   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :123   1st Qu.:39.50   1st Qu.:15.60  \n Gentoo   :119   Torgersen: 47   Median :44.50   Median :17.30  \n                                 Mean   :43.99   Mean   :17.16  \n                                 3rd Qu.:48.60   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172       Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190       1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197       Median :4050                Median :2008  \n Mean   :201       Mean   :4207                Mean   :2008  \n 3rd Qu.:213       3rd Qu.:4775                3rd Qu.:2009  \n Max.   :231       Max.   :6300                Max.   :2009  \n\n\n\n\n\n\n\nlibrary(nlme)\nsummary(Glucose)\n\n Subject      Time            conc          Meal   \n 6:63    Min.   :-0.25   Min.   : 2.070   2am :66  \n 2:63    1st Qu.: 0.50   1st Qu.: 4.348   6am :66  \n 3:63    Median : 2.00   Median : 4.900   10am:60  \n 5:63    Mean   : 2.50   Mean   : 5.511   2pm :60  \n 1:63    3rd Qu.: 4.00   3rd Qu.: 6.357   6pm :60  \n 4:63    Max.   : 7.00   Max.   :10.470   10pm:66  \n                         NA's   :2                 \n\n#Drop all NA's\nGlucose_noNA &lt;- Glucose %&gt;% drop_na()\nsummary(Glucose_noNA)\n\n Subject      Time             conc          Meal   \n 6:62    Min.   :-0.250   Min.   : 2.070   2am :65  \n 2:63    1st Qu.: 0.500   1st Qu.: 4.348   6am :66  \n 3:63    Median : 2.000   Median : 4.900   10am:59  \n 5:63    Mean   : 2.484   Mean   : 5.511   2pm :60  \n 1:63    3rd Qu.: 4.000   3rd Qu.: 6.357   6pm :60  \n 4:62    Max.   : 7.000   Max.   :10.470   10pm:66  \n\n\n\n\n\nDoes having NA’s in the graph make sense?\n\nggplot(data = penguins, \n       aes(x = species, fill = species)) + \n    geom_bar() +\n  facet_wrap(vars(sex)) +\n  labs( x = \"Species\",\n        y = \"Count\",\n        title = \"Frequency of Species by Sex\")\n\n\n\n\nDoes having NA’s in the graph make a difference?\n\nggplot(data = Glucose,\n       aes(x = Subject, y = conc)) +\n  geom_boxplot() +\n  labs(x = \"Subject Number\", \n       y = \"Glucose Concentration\",\n       title = \"Boxplot of Glucose by Subject\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\nI find this tool very helpful, but it must be used with care. Some modeling techniques will not work with missing values, so it is necessary to find a solution for this. However, dropping all NA’s in all columns can drastically reduce the size of your dataset. There are several things to consider before dropping NA’s:\n\nHow many NA’s are in your dataset? How much data do you lose if you drop them?\nWhat types of data have NA’s?\nAre the NA’s in the variables you will be considering?\nDoes the modeling technique you want to use accept NA’s?\nDoes the graph you want to generate make sense with NA’s?"
  },
  {
    "objectID": "Function_of_the_Week_Weingarten.html#what-is-it-for",
    "href": "Function_of_the_Week_Weingarten.html#what-is-it-for",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "The drop_na function will drop out rows from your dataset where columns contain missing values. It can take two arguments:\n\ndata : the name of your dataframe\n... : Columns to inspect for missing values. If not specified, all columns are inspected.\n\nExample code setup: data %&gt;% drop_na() or data %&gt;% drop_na(column_name)"
  },
  {
    "objectID": "Function_of_the_Week_Weingarten.html#example-with-penguins-dataset",
    "href": "Function_of_the_Week_Weingarten.html#example-with-penguins-dataset",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "#How many NA's in our dataset?\n(sum(is.na(penguins)))\n\n[1] 19\n\n#What columns contain NA's?\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\n\n\n\n#Drop NA's from just one column\npenguins_dropNA_mass &lt;- penguins %&gt;% drop_na(body_mass_g)\nsummary(penguins_dropNA_mass)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :151   Biscoe   :167   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :123   Torgersen: 51   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  :  9   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n\n\n\n\n\n\n#Drop NA's from all columns\npenguins_dropNA_all &lt;- penguins %&gt;% drop_na()\nsummary(penguins_dropNA_all)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :146   Biscoe   :163   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :123   1st Qu.:39.50   1st Qu.:15.60  \n Gentoo   :119   Torgersen: 47   Median :44.50   Median :17.30  \n                                 Mean   :43.99   Mean   :17.16  \n                                 3rd Qu.:48.60   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172       Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190       1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197       Median :4050                Median :2008  \n Mean   :201       Mean   :4207                Mean   :2008  \n 3rd Qu.:213       3rd Qu.:4775                3rd Qu.:2009  \n Max.   :231       Max.   :6300                Max.   :2009"
  },
  {
    "objectID": "Function_of_the_Week_Weingarten.html#example-with-glucose-dataset",
    "href": "Function_of_the_Week_Weingarten.html#example-with-glucose-dataset",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "library(nlme)\nsummary(Glucose)\n\n Subject      Time            conc          Meal   \n 6:63    Min.   :-0.25   Min.   : 2.070   2am :66  \n 2:63    1st Qu.: 0.50   1st Qu.: 4.348   6am :66  \n 3:63    Median : 2.00   Median : 4.900   10am:60  \n 5:63    Mean   : 2.50   Mean   : 5.511   2pm :60  \n 1:63    3rd Qu.: 4.00   3rd Qu.: 6.357   6pm :60  \n 4:63    Max.   : 7.00   Max.   :10.470   10pm:66  \n                         NA's   :2                 \n\n#Drop all NA's\nGlucose_noNA &lt;- Glucose %&gt;% drop_na()\nsummary(Glucose_noNA)\n\n Subject      Time             conc          Meal   \n 6:62    Min.   :-0.250   Min.   : 2.070   2am :65  \n 2:63    1st Qu.: 0.500   1st Qu.: 4.348   6am :66  \n 3:63    Median : 2.000   Median : 4.900   10am:59  \n 5:63    Mean   : 2.484   Mean   : 5.511   2pm :60  \n 1:63    3rd Qu.: 4.000   3rd Qu.: 6.357   6pm :60  \n 4:62    Max.   : 7.000   Max.   :10.470   10pm:66"
  },
  {
    "objectID": "Function_of_the_Week_Weingarten.html#graphical-considerations",
    "href": "Function_of_the_Week_Weingarten.html#graphical-considerations",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "Does having NA’s in the graph make sense?\n\nggplot(data = penguins, \n       aes(x = species, fill = species)) + \n    geom_bar() +\n  facet_wrap(vars(sex)) +\n  labs( x = \"Species\",\n        y = \"Count\",\n        title = \"Frequency of Species by Sex\")\n\n\n\n\nDoes having NA’s in the graph make a difference?\n\nggplot(data = Glucose,\n       aes(x = Subject, y = conc)) +\n  geom_boxplot() +\n  labs(x = \"Subject Number\", \n       y = \"Glucose Concentration\",\n       title = \"Boxplot of Glucose by Subject\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "Function_of_the_Week_Weingarten.html#is-it-helpful",
    "href": "Function_of_the_Week_Weingarten.html#is-it-helpful",
    "title": "tidyr::drop_na()",
    "section": "",
    "text": "I find this tool very helpful, but it must be used with care. Some modeling techniques will not work with missing values, so it is necessary to find a solution for this. However, dropping all NA’s in all columns can drastically reduce the size of your dataset. There are several things to consider before dropping NA’s:\n\nHow many NA’s are in your dataset? How much data do you lose if you drop them?\nWhat types of data have NA’s?\nAre the NA’s in the variables you will be considering?\nDoes the modeling technique you want to use accept NA’s?\nDoes the graph you want to generate make sense with NA’s?"
  }
]